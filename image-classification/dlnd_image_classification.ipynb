{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "# floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "# if isfile(floyd_cifar10_location):\n",
    "#     tar_gz_path = floyd_cifar10_location\n",
    "# else:\n",
    "tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rYA5vNbropkjJJmYIs\nUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2QttzI2Bc5gChYPn2Z88\nEd+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+w79fZebGx9PwTK+f\n+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X18MylKzupXec34t/t\n83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNogN3dhMAjPDPuL1K5p\n4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8AAPzTJegBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+te3P84NddfxJuT\nBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3X6R2HXXiTWOT03Fq\n15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvhmadP7qd2jceH4Zmj\no1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr92iLeKFCtzNMrXr2\n28epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrlilR+983545sblXCHI\nZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5izdSc4tBvPRotJYr\n3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWvtdb2DuPf7eB0ltq1\nSpz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjdevZOa6w/j7V+f+1yu\nGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1vz4/jz8ZL41zD3q3e\nYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJl6SMOrnbara5Fp+Z\n58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj6+GZ3cePUrv+9b/5\nVnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0jz/jvvjP42fYWmvj\n2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvHw5PwzHKwSO364z+K\nN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVprrf3oe99Nzb333p3w\nzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7r4Rntq/dTO16+jx+\n9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1lfGZ9tErt+uZ2/Ozf\nvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39z8Iz2ebAH/7q3fDM\new8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJj5+ldj1+/GF45qt/\nkXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKdy+/Hz2Ptw4epXYvl\nLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI7TrfOxeemRzn7vtL\n8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye74ZmP3n8/tesseKMH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx7\n3Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUaozjL++VprLd5z9Q8m\n3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fItzdyrXzTzjA1t7h5\nLTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUepuck8XoIx7uWKRE4u\nxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+42owiM+kNuXm+ldf\nSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX4Znzb72e2vX8Ua64\nazq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwzuriT2vV8fJiau95b\nC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZabzIJz0ye5u6ptpZr\nlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ49SurUtbqbnd7XhL\n5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr21dTu9Yu5hqh1g7i\nzXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0SLYCn3Vxz4NafvZma\nO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYepXdsn8V2ttXbhbrxp\n85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa+8Gnn4Vnbp4epna9\n0eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/miunOe6eS82NH9wL\nzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m5rZ34mU4Xz13N7Xr\nb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7z7/4P+GZL1zOtZP9\nx/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte04ePU3PnEq1mneU0\ntasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8vroyij9zWmvtK196\nLTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH/cEoPLO9mqd2Tbu5\nudVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq1/G9++GZxTh+vVpr\nbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwze/Db1K6z4I0eAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdcPV\nMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1cw2RrVWce/8lMl/HG\nu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2ujXOH353n3rfG8/g5\nnixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8QnrnaPU3tujjeC8/0\nnzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx6bf4ZxyNNlK7fvPh\nvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fNpsfxXbuLw9Su0eh8\nau5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvWchqe2XjyKLVrfXaS\nmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LNcK9c3AnPnC72U7v6\nm8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDXyre8fDE1d9ri+x49\njbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1hXx7kWte2+vFWvtZa\ne/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXtxx8Fy16ure3x81wD\n44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3Nk7NPXx0FN+1Hm/l\na621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW31YsXdcwO4wUYrbW2\n6MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWKiFYffhKeGSXfZaaj\n8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2LQbx73b34nZq11nw\nRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY\n2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H3jJex7U3zTUHXhnF\nm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bnB6lda2vxlsjPTnPN\ncM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh7jlwFrzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbaTJJlJ5fWO+GZ\nP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK11gbr8e+2WuZKS1pi\nbmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj6/34gezPcoUxx8/j\nz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd2M41hv2Lly+EZw6m\n8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K743dHa/PHT1K7zi3l4\nZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4w961fvz33FpriQLR\n1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+/E9vnEvtOp7kPuN8\nHG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+btlp7jxWj56EZ15q\nuefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHldW06OU7tuvHk1PPPy\nndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab8XKP0+R1nq1yc91l\n/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtkWc/6YpCaW82m4ZlH\n67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM111sfhWeme0epXZlW\ns5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xXuba27ir+8zzu5Nra\nTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d1ge5+rrlIt5C11pr\nm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqttXbnRq4M5+PP4gUT\n08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/oJQp0srJvMoMWv86P\nl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrHi8wmybIepTYAwP+X\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhdVtr1vm\n/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySbxi4miujOJxoRW2tt\nM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzNU7umi/h5bCTvjwvn\ncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyzGucakFruONrVzfhn\n/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa611jqJVr7WWuv3441h\ni1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOtuxWe6Sz/cHHrjR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21KY7iBdg\ntNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3P243MTfv50pLjpfx\nuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJss5N8DuTGWmvxwcn4\nOLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD9762Zq1/5JfNfPPnmW\n2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+vI1u7lk16safBVv9\n3OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHOfD5LrVomL3WmvOHG\nKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFLa611e/Hv1VprvcRc\nsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3crttks/hw46cTP8Kx4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\ns8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlHN40TWAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb920266a0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None,*image_shape), name = 'x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name = 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None), name = 'keep_prob')\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# tests.test_nn_image_inputs(neural_net_image_input)\n",
    "# tests.test_nn_label_inputs(neural_net_label_input)\n",
    "# tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides, padding = 'SAME'):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    with tf.name_scope('Conv2d_maxpool'):\n",
    "        W = tf.Variable(tf.truncated_normal(shape = (*conv_ksize, x_tensor.get_shape().as_list()[3],conv_num_outputs), \n",
    "                                            mean=0.0, \n",
    "                                            stddev=0.1,\n",
    "                                            dtype=tf.float32, \n",
    "                                            name = 'conv_W'))\n",
    "        b = tf.Variable(tf.zeros(conv_num_outputs, \n",
    "                                 dtype=tf.float32,\n",
    "                                 name = 'conv_b'))\n",
    "        conv = tf.nn.conv2d(x_tensor, W, [1, *conv_strides ,1], padding, name = 'conv2d')\n",
    "        conv += b\n",
    "        conv = tf.nn.relu(conv)\n",
    "        tf.summary.histogram(\"conv_weights\", W)\n",
    "        tf.summary.histogram(\"conv_bias\", b)\n",
    "        max_pooled_conv = tf.nn.max_pool(conv, [1, *pool_ksize ,1], [1, *pool_strides ,1], padding, name='max_pool')\n",
    "        return max_pooled_conv\n",
    "\n",
    "# tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    with tf.name_scope('Flatten'):\n",
    "        return tf.reshape(x_tensor, shape = (-1 ,np.prod(x_tensor.get_shape().as_list()[1:])), name = 'flatten')\n",
    "\n",
    "# tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('FC'):\n",
    "        W = tf.Variable(tf.truncated_normal(shape = (x_tensor.get_shape().as_list()[1], num_outputs), \n",
    "                                            mean=0.0,\n",
    "                                            stddev=0.1,\n",
    "                                            dtype=tf.float32, \n",
    "                                            name = 'FC_W'))\n",
    "        b = tf.Variable(tf.zeros(num_outputs, \n",
    "                                 dtype=tf.float32,\n",
    "                                 name = 'FC_b'))\n",
    "        fc = tf.matmul(x_tensor, W) + b\n",
    "        fc_act = tf.nn.relu(fc)\n",
    "        tf.summary.histogram(\"FC_weights\", W)\n",
    "        tf.summary.histogram(\"FC_bias\", b)\n",
    "        return fc_act\n",
    "\n",
    "# tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('Output'):\n",
    "        W = tf.Variable(tf.truncated_normal(shape = (x_tensor.get_shape().as_list()[1], num_outputs), \n",
    "                                            mean=0.0,\n",
    "                                            stddev=0.1,\n",
    "                                            dtype=tf.float32, \n",
    "                                            name = 'Out_W'))\n",
    "        b = tf.Variable(tf.zeros(num_outputs, \n",
    "                                 dtype=tf.float32,\n",
    "                                 name = 'Out_b'))\n",
    "        fc = tf.matmul(x_tensor, W) + b\n",
    "        tf.summary.histogram(\"Output_weights\", W)\n",
    "        tf.summary.histogram(\"Output_bias\", b)\n",
    "        return fc\n",
    "\n",
    "# tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net_1(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "\n",
    "    l1 = conv2d_maxpool(x, \n",
    "                        conv_num_outputs = 16, \n",
    "                        conv_ksize = (1,1), \n",
    "                        conv_strides = (1,1), \n",
    "                        pool_ksize  = (2,2), \n",
    "                        pool_strides = (2,2))\n",
    "    l1 = tf.contrib.layers.batch_norm(l1)\n",
    "    \n",
    "    l2 = conv2d_maxpool(l1, \n",
    "                        conv_num_outputs = 32, \n",
    "                        conv_ksize = (3,3), \n",
    "                        conv_strides = (1,1), \n",
    "                        pool_ksize  = (2,2), \n",
    "                        pool_strides = (2,2))\n",
    "    l2 = tf.contrib.layers.batch_norm(l2)\n",
    "    \n",
    "    l3 = conv2d_maxpool(l2, \n",
    "                    conv_num_outputs = 64, \n",
    "                    conv_ksize = (3,3), \n",
    "                    conv_strides = (1,1), \n",
    "                    pool_ksize  = (2,2), \n",
    "                    pool_strides = (2,2))\n",
    "    l3 = tf.contrib.layers.batch_norm(l3)\n",
    "    \n",
    "    l4 = flatten(l3)\n",
    "    l4 = tf.nn.dropout(l4, keep_prob)\n",
    "    \n",
    "    l5 = fully_conn(l4, 512)\n",
    "    l5 = tf.nn.dropout(l5, keep_prob)\n",
    "    \n",
    "    l6 = fully_conn(l5, 256)\n",
    "    \n",
    "    return output(l6, 10)\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net_1(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "with tf.name_scope('Xent'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    tf.summary.scalar('softmax_cross_entropy_with_logits', cost)\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    with tf.name_scope('adam'):\n",
    "        return session.run([optimizer], feed_dict = {x: feature_batch, y:label_batch, keep_prob: keep_probability})\n",
    "\n",
    "# tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    with tf.name_scope('stats'):\n",
    "        loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "        t_acc = session.run(accuracy, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "        v_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "        print(f'Loss: {loss:.5f} Training accuracy: {t_acc:.5f} Validation accuracy: {v_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "keep_probability = 0.6\n",
    "\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 1.96911 Training accuracy: 0.30000 Validation accuracy: 0.30960\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 1.87559 Training accuracy: 0.27500 Validation accuracy: 0.32220\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.80088 Training accuracy: 0.42500 Validation accuracy: 0.34160\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.80499 Training accuracy: 0.32500 Validation accuracy: 0.37080\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.75126 Training accuracy: 0.40000 Validation accuracy: 0.37360\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.84196 Training accuracy: 0.40000 Validation accuracy: 0.40460\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.75397 Training accuracy: 0.35000 Validation accuracy: 0.42140\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.47213 Training accuracy: 0.42500 Validation accuracy: 0.42420\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.56159 Training accuracy: 0.47500 Validation accuracy: 0.44060\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.56908 Training accuracy: 0.45000 Validation accuracy: 0.45420\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.66317 Training accuracy: 0.47500 Validation accuracy: 0.45860\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.55062 Training accuracy: 0.47500 Validation accuracy: 0.46700\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.22386 Training accuracy: 0.55000 Validation accuracy: 0.47720\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.39846 Training accuracy: 0.45000 Validation accuracy: 0.48860\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.49216 Training accuracy: 0.45000 Validation accuracy: 0.48540\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.52045 Training accuracy: 0.55000 Validation accuracy: 0.50020\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.38664 Training accuracy: 0.52500 Validation accuracy: 0.50320\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.07807 Training accuracy: 0.65000 Validation accuracy: 0.50800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.27171 Training accuracy: 0.55000 Validation accuracy: 0.50960\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.44310 Training accuracy: 0.47500 Validation accuracy: 0.52280\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.41373 Training accuracy: 0.57500 Validation accuracy: 0.52400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.37937 Training accuracy: 0.52500 Validation accuracy: 0.52720\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 0.98276 Training accuracy: 0.70000 Validation accuracy: 0.52640\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.16565 Training accuracy: 0.57500 Validation accuracy: 0.52980\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.37180 Training accuracy: 0.52500 Validation accuracy: 0.54660\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.38475 Training accuracy: 0.57500 Validation accuracy: 0.54740\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.27919 Training accuracy: 0.60000 Validation accuracy: 0.55340\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 0.93126 Training accuracy: 0.67500 Validation accuracy: 0.55660\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.09936 Training accuracy: 0.57500 Validation accuracy: 0.56020\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.21289 Training accuracy: 0.62500 Validation accuracy: 0.57180\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.31715 Training accuracy: 0.57500 Validation accuracy: 0.57400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.30042 Training accuracy: 0.57500 Validation accuracy: 0.58620\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.86433 Training accuracy: 0.72500 Validation accuracy: 0.57260\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.10692 Training accuracy: 0.60000 Validation accuracy: 0.59460\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.14426 Training accuracy: 0.60000 Validation accuracy: 0.60140\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.22417 Training accuracy: 0.55000 Validation accuracy: 0.59360\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.14346 Training accuracy: 0.65000 Validation accuracy: 0.60640\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.81356 Training accuracy: 0.75000 Validation accuracy: 0.59740\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.02346 Training accuracy: 0.60000 Validation accuracy: 0.59660\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.17305 Training accuracy: 0.57500 Validation accuracy: 0.60960\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.12221 Training accuracy: 0.60000 Validation accuracy: 0.61580\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.12403 Training accuracy: 0.62500 Validation accuracy: 0.62440\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.74789 Training accuracy: 0.72500 Validation accuracy: 0.62040\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.99309 Training accuracy: 0.62500 Validation accuracy: 0.62200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.07796 Training accuracy: 0.67500 Validation accuracy: 0.62940\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.15882 Training accuracy: 0.57500 Validation accuracy: 0.62400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.03926 Training accuracy: 0.65000 Validation accuracy: 0.63600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.75217 Training accuracy: 0.75000 Validation accuracy: 0.62600\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.97581 Training accuracy: 0.62500 Validation accuracy: 0.62820\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.02838 Training accuracy: 0.67500 Validation accuracy: 0.63460\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.08389 Training accuracy: 0.57500 Validation accuracy: 0.63580\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.06921 Training accuracy: 0.70000 Validation accuracy: 0.64380\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.77803 Training accuracy: 0.75000 Validation accuracy: 0.64060\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.94490 Training accuracy: 0.62500 Validation accuracy: 0.64640\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.95817 Training accuracy: 0.70000 Validation accuracy: 0.64600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.03180 Training accuracy: 0.60000 Validation accuracy: 0.64880\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.04743 Training accuracy: 0.62500 Validation accuracy: 0.65480\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.69040 Training accuracy: 0.77500 Validation accuracy: 0.64520\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.91634 Training accuracy: 0.65000 Validation accuracy: 0.65220\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.96035 Training accuracy: 0.67500 Validation accuracy: 0.65720\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.98032 Training accuracy: 0.67500 Validation accuracy: 0.64820\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.94272 Training accuracy: 0.70000 Validation accuracy: 0.65900\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.70843 Training accuracy: 0.77500 Validation accuracy: 0.65040\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.88016 Training accuracy: 0.70000 Validation accuracy: 0.65560\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.90102 Training accuracy: 0.72500 Validation accuracy: 0.66680\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.05328 Training accuracy: 0.62500 Validation accuracy: 0.66460\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.98568 Training accuracy: 0.70000 Validation accuracy: 0.67040\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.66865 Training accuracy: 0.82500 Validation accuracy: 0.66460\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.90308 Training accuracy: 0.70000 Validation accuracy: 0.66140\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.89784 Training accuracy: 0.72500 Validation accuracy: 0.66920\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.95205 Training accuracy: 0.62500 Validation accuracy: 0.67080\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.89533 Training accuracy: 0.67500 Validation accuracy: 0.66420\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.64639 Training accuracy: 0.82500 Validation accuracy: 0.66760\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.85795 Training accuracy: 0.75000 Validation accuracy: 0.66640\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.88721 Training accuracy: 0.65000 Validation accuracy: 0.68140\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.92105 Training accuracy: 0.67500 Validation accuracy: 0.67700\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.89939 Training accuracy: 0.72500 Validation accuracy: 0.67020\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.66190 Training accuracy: 0.82500 Validation accuracy: 0.67300\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.79534 Training accuracy: 0.72500 Validation accuracy: 0.67320\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.83242 Training accuracy: 0.77500 Validation accuracy: 0.67900\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.88288 Training accuracy: 0.62500 Validation accuracy: 0.68140\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.91503 Training accuracy: 0.67500 Validation accuracy: 0.67460\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.64905 Training accuracy: 0.85000 Validation accuracy: 0.67260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.75636 Training accuracy: 0.75000 Validation accuracy: 0.67800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.76820 Training accuracy: 0.80000 Validation accuracy: 0.69200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.91905 Training accuracy: 0.67500 Validation accuracy: 0.67820\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.88081 Training accuracy: 0.70000 Validation accuracy: 0.68500\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.62089 Training accuracy: 0.80000 Validation accuracy: 0.68380\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.76393 Training accuracy: 0.72500 Validation accuracy: 0.68140\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.79279 Training accuracy: 0.75000 Validation accuracy: 0.69640\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.91021 Training accuracy: 0.65000 Validation accuracy: 0.68940\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.87905 Training accuracy: 0.70000 Validation accuracy: 0.68900\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.57100 Training accuracy: 0.85000 Validation accuracy: 0.68880\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.76843 Training accuracy: 0.75000 Validation accuracy: 0.68440\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.80868 Training accuracy: 0.72500 Validation accuracy: 0.68380\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.86435 Training accuracy: 0.67500 Validation accuracy: 0.69000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.87925 Training accuracy: 0.67500 Validation accuracy: 0.69620\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.61522 Training accuracy: 0.82500 Validation accuracy: 0.68660\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.73293 Training accuracy: 0.77500 Validation accuracy: 0.69060\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.71700 Training accuracy: 0.80000 Validation accuracy: 0.69860\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.82978 Training accuracy: 0.65000 Validation accuracy: 0.69280\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.87880 Training accuracy: 0.75000 Validation accuracy: 0.69340\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.61617 Training accuracy: 0.82500 Validation accuracy: 0.69500\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.72303 Training accuracy: 0.82500 Validation accuracy: 0.69360\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.71763 Training accuracy: 0.82500 Validation accuracy: 0.69760\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.81679 Training accuracy: 0.67500 Validation accuracy: 0.70080\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.78881 Training accuracy: 0.70000 Validation accuracy: 0.69540\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.56024 Training accuracy: 0.85000 Validation accuracy: 0.69200\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.65855 Training accuracy: 0.82500 Validation accuracy: 0.69620\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.70057 Training accuracy: 0.82500 Validation accuracy: 0.70140\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.79688 Training accuracy: 0.72500 Validation accuracy: 0.70300\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.83442 Training accuracy: 0.72500 Validation accuracy: 0.70340\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.52478 Training accuracy: 0.87500 Validation accuracy: 0.69960\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.67701 Training accuracy: 0.82500 Validation accuracy: 0.69860\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.66518 Training accuracy: 0.77500 Validation accuracy: 0.70240\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.72923 Training accuracy: 0.75000 Validation accuracy: 0.70360\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.81865 Training accuracy: 0.72500 Validation accuracy: 0.70060\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.51966 Training accuracy: 0.87500 Validation accuracy: 0.70400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.62499 Training accuracy: 0.85000 Validation accuracy: 0.69900\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.69224 Training accuracy: 0.82500 Validation accuracy: 0.70520\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.72670 Training accuracy: 0.75000 Validation accuracy: 0.70740\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.75752 Training accuracy: 0.70000 Validation accuracy: 0.70040\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.48604 Training accuracy: 0.85000 Validation accuracy: 0.70240\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.63259 Training accuracy: 0.85000 Validation accuracy: 0.70500\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.67216 Training accuracy: 0.82500 Validation accuracy: 0.70580\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.75480 Training accuracy: 0.77500 Validation accuracy: 0.70980\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.78883 Training accuracy: 0.75000 Validation accuracy: 0.70760\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.51056 Training accuracy: 0.85000 Validation accuracy: 0.70240\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.61540 Training accuracy: 0.82500 Validation accuracy: 0.71020\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.65686 Training accuracy: 0.75000 Validation accuracy: 0.70860\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.79377 Training accuracy: 0.70000 Validation accuracy: 0.70960\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.79901 Training accuracy: 0.70000 Validation accuracy: 0.71500\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.48839 Training accuracy: 0.87500 Validation accuracy: 0.70620\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.63275 Training accuracy: 0.85000 Validation accuracy: 0.69840\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.61714 Training accuracy: 0.85000 Validation accuracy: 0.70940\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.75791 Training accuracy: 0.70000 Validation accuracy: 0.71020\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.68409 Training accuracy: 0.77500 Validation accuracy: 0.70420\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.49844 Training accuracy: 0.87500 Validation accuracy: 0.71320\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.59761 Training accuracy: 0.85000 Validation accuracy: 0.71000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.58954 Training accuracy: 0.85000 Validation accuracy: 0.71460\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.76298 Training accuracy: 0.75000 Validation accuracy: 0.72100\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.66454 Training accuracy: 0.77500 Validation accuracy: 0.71580\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.46900 Training accuracy: 0.87500 Validation accuracy: 0.71280\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.56965 Training accuracy: 0.87500 Validation accuracy: 0.70520\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.59724 Training accuracy: 0.82500 Validation accuracy: 0.71900\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.74561 Training accuracy: 0.80000 Validation accuracy: 0.71680\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.67906 Training accuracy: 0.72500 Validation accuracy: 0.71620\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.46591 Training accuracy: 0.85000 Validation accuracy: 0.71960\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.56772 Training accuracy: 0.85000 Validation accuracy: 0.72080\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.54402 Training accuracy: 0.90000 Validation accuracy: 0.72340\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.72237 Training accuracy: 0.72500 Validation accuracy: 0.72360\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.69756 Training accuracy: 0.77500 Validation accuracy: 0.72260\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.50827 Training accuracy: 0.85000 Validation accuracy: 0.72240\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.57799 Training accuracy: 0.82500 Validation accuracy: 0.71980\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.60627 Training accuracy: 0.77500 Validation accuracy: 0.71600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.76790 Training accuracy: 0.72500 Validation accuracy: 0.70960\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.68194 Training accuracy: 0.77500 Validation accuracy: 0.71560\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.44426 Training accuracy: 0.87500 Validation accuracy: 0.71860\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.61277 Training accuracy: 0.90000 Validation accuracy: 0.71880\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.61798 Training accuracy: 0.85000 Validation accuracy: 0.71860\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.73822 Training accuracy: 0.77500 Validation accuracy: 0.71860\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.64276 Training accuracy: 0.80000 Validation accuracy: 0.72220\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.43091 Training accuracy: 0.87500 Validation accuracy: 0.72740\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.58048 Training accuracy: 0.85000 Validation accuracy: 0.72260\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.59795 Training accuracy: 0.77500 Validation accuracy: 0.72880\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.68482 Training accuracy: 0.72500 Validation accuracy: 0.71500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.75390 Training accuracy: 0.72500 Validation accuracy: 0.71720\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.42551 Training accuracy: 0.87500 Validation accuracy: 0.71580\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.54341 Training accuracy: 0.87500 Validation accuracy: 0.71880\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.56798 Training accuracy: 0.85000 Validation accuracy: 0.72740\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.67464 Training accuracy: 0.77500 Validation accuracy: 0.71840\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.66245 Training accuracy: 0.82500 Validation accuracy: 0.72520\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.43755 Training accuracy: 0.87500 Validation accuracy: 0.72320\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.59709 Training accuracy: 0.80000 Validation accuracy: 0.71440\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.52027 Training accuracy: 0.87500 Validation accuracy: 0.72500\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.68729 Training accuracy: 0.75000 Validation accuracy: 0.73100\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.78336 Training accuracy: 0.72500 Validation accuracy: 0.72580\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.36749 Training accuracy: 0.87500 Validation accuracy: 0.72640\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.55783 Training accuracy: 0.87500 Validation accuracy: 0.72260\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.55220 Training accuracy: 0.80000 Validation accuracy: 0.72340\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.62606 Training accuracy: 0.77500 Validation accuracy: 0.72660\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.67562 Training accuracy: 0.77500 Validation accuracy: 0.72180\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.37758 Training accuracy: 0.87500 Validation accuracy: 0.72380\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.56198 Training accuracy: 0.85000 Validation accuracy: 0.72260\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.57462 Training accuracy: 0.77500 Validation accuracy: 0.73220\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.71378 Training accuracy: 0.77500 Validation accuracy: 0.72860\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.67639 Training accuracy: 0.77500 Validation accuracy: 0.72180\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.41749 Training accuracy: 0.87500 Validation accuracy: 0.72840\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.51677 Training accuracy: 0.90000 Validation accuracy: 0.72640\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.54345 Training accuracy: 0.82500 Validation accuracy: 0.71860\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.68112 Training accuracy: 0.77500 Validation accuracy: 0.72740\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.72580 Training accuracy: 0.75000 Validation accuracy: 0.72940\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.43033 Training accuracy: 0.90000 Validation accuracy: 0.72180\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.52258 Training accuracy: 0.85000 Validation accuracy: 0.72420\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.50136 Training accuracy: 0.90000 Validation accuracy: 0.73220\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.70169 Training accuracy: 0.70000 Validation accuracy: 0.72220\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.66820 Training accuracy: 0.75000 Validation accuracy: 0.72820\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.35050 Training accuracy: 0.90000 Validation accuracy: 0.72100\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.54380 Training accuracy: 0.87500 Validation accuracy: 0.71420\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.53585 Training accuracy: 0.85000 Validation accuracy: 0.72540\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.64207 Training accuracy: 0.77500 Validation accuracy: 0.72740\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.71085 Training accuracy: 0.75000 Validation accuracy: 0.72460\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.39676 Training accuracy: 0.87500 Validation accuracy: 0.72920\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.49826 Training accuracy: 0.87500 Validation accuracy: 0.73080\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.47773 Training accuracy: 0.87500 Validation accuracy: 0.73000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.61109 Training accuracy: 0.85000 Validation accuracy: 0.72460\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.63582 Training accuracy: 0.77500 Validation accuracy: 0.72840\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.41132 Training accuracy: 0.87500 Validation accuracy: 0.72560\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.50195 Training accuracy: 0.87500 Validation accuracy: 0.73640\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.49374 Training accuracy: 0.90000 Validation accuracy: 0.73740\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.65660 Training accuracy: 0.75000 Validation accuracy: 0.73720\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.61562 Training accuracy: 0.82500 Validation accuracy: 0.73360\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.40208 Training accuracy: 0.90000 Validation accuracy: 0.73360\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.48787 Training accuracy: 0.90000 Validation accuracy: 0.72920\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.49080 Training accuracy: 0.87500 Validation accuracy: 0.73460\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.63582 Training accuracy: 0.80000 Validation accuracy: 0.72940\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.56213 Training accuracy: 0.85000 Validation accuracy: 0.73300\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.38884 Training accuracy: 0.87500 Validation accuracy: 0.72540\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.50210 Training accuracy: 0.87500 Validation accuracy: 0.73140\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.48746 Training accuracy: 0.90000 Validation accuracy: 0.73680\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.66981 Training accuracy: 0.75000 Validation accuracy: 0.73440\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.59884 Training accuracy: 0.80000 Validation accuracy: 0.74120\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.40337 Training accuracy: 0.85000 Validation accuracy: 0.73140\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.47562 Training accuracy: 0.87500 Validation accuracy: 0.73680\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.44950 Training accuracy: 0.92500 Validation accuracy: 0.73220\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.65868 Training accuracy: 0.77500 Validation accuracy: 0.73240\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.54552 Training accuracy: 0.82500 Validation accuracy: 0.74240\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.35152 Training accuracy: 0.87500 Validation accuracy: 0.73420\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.51219 Training accuracy: 0.87500 Validation accuracy: 0.73480\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.45933 Training accuracy: 0.90000 Validation accuracy: 0.73840\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.62667 Training accuracy: 0.72500 Validation accuracy: 0.73460\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.58633 Training accuracy: 0.82500 Validation accuracy: 0.73780\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.32169 Training accuracy: 0.92500 Validation accuracy: 0.74320\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.49129 Training accuracy: 0.85000 Validation accuracy: 0.73700\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.44430 Training accuracy: 0.90000 Validation accuracy: 0.72760\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.65684 Training accuracy: 0.77500 Validation accuracy: 0.74060\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.63774 Training accuracy: 0.85000 Validation accuracy: 0.73560\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.34324 Training accuracy: 0.90000 Validation accuracy: 0.73780\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.47380 Training accuracy: 0.87500 Validation accuracy: 0.73440\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.51400 Training accuracy: 0.82500 Validation accuracy: 0.73460\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.61204 Training accuracy: 0.82500 Validation accuracy: 0.73740\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.59405 Training accuracy: 0.77500 Validation accuracy: 0.73860\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.38589 Training accuracy: 0.90000 Validation accuracy: 0.73200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.50988 Training accuracy: 0.87500 Validation accuracy: 0.73800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.45602 Training accuracy: 0.82500 Validation accuracy: 0.74140\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.57774 Training accuracy: 0.80000 Validation accuracy: 0.73380\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.59191 Training accuracy: 0.82500 Validation accuracy: 0.73680\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.39829 Training accuracy: 0.87500 Validation accuracy: 0.73840\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.48392 Training accuracy: 0.90000 Validation accuracy: 0.73620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.45443 Training accuracy: 0.90000 Validation accuracy: 0.74220\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.59067 Training accuracy: 0.75000 Validation accuracy: 0.73760\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.56279 Training accuracy: 0.87500 Validation accuracy: 0.73660\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.39247 Training accuracy: 0.87500 Validation accuracy: 0.73540\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.47578 Training accuracy: 0.87500 Validation accuracy: 0.73460\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.46387 Training accuracy: 0.87500 Validation accuracy: 0.74740\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.57276 Training accuracy: 0.75000 Validation accuracy: 0.73780\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.57840 Training accuracy: 0.80000 Validation accuracy: 0.74480\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.31288 Training accuracy: 0.92500 Validation accuracy: 0.74420\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.47139 Training accuracy: 0.90000 Validation accuracy: 0.74900\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.49591 Training accuracy: 0.82500 Validation accuracy: 0.73660\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.59253 Training accuracy: 0.75000 Validation accuracy: 0.74620\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.56172 Training accuracy: 0.85000 Validation accuracy: 0.74200\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.34383 Training accuracy: 0.90000 Validation accuracy: 0.74360\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.48334 Training accuracy: 0.90000 Validation accuracy: 0.73960\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.46527 Training accuracy: 0.87500 Validation accuracy: 0.74140\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.58950 Training accuracy: 0.77500 Validation accuracy: 0.74060\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.49729 Training accuracy: 0.90000 Validation accuracy: 0.74020\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.33868 Training accuracy: 0.90000 Validation accuracy: 0.73660\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.46313 Training accuracy: 0.87500 Validation accuracy: 0.74340\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.41205 Training accuracy: 0.87500 Validation accuracy: 0.74020\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.60825 Training accuracy: 0.80000 Validation accuracy: 0.74240\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.51914 Training accuracy: 0.92500 Validation accuracy: 0.74180\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.35252 Training accuracy: 0.90000 Validation accuracy: 0.74840\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.44156 Training accuracy: 0.87500 Validation accuracy: 0.74600\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.45115 Training accuracy: 0.90000 Validation accuracy: 0.74820\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.60410 Training accuracy: 0.77500 Validation accuracy: 0.74100\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.62927 Training accuracy: 0.82500 Validation accuracy: 0.73840\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.32722 Training accuracy: 0.92500 Validation accuracy: 0.75380\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.47302 Training accuracy: 0.87500 Validation accuracy: 0.74020\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.45671 Training accuracy: 0.87500 Validation accuracy: 0.74700\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.58432 Training accuracy: 0.75000 Validation accuracy: 0.74080\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.52383 Training accuracy: 0.85000 Validation accuracy: 0.74400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.32016 Training accuracy: 0.92500 Validation accuracy: 0.74280\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.41478 Training accuracy: 0.90000 Validation accuracy: 0.74540\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.46115 Training accuracy: 0.85000 Validation accuracy: 0.74680\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.53464 Training accuracy: 0.82500 Validation accuracy: 0.74700\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.60072 Training accuracy: 0.82500 Validation accuracy: 0.74060\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.30812 Training accuracy: 0.90000 Validation accuracy: 0.74040\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.46429 Training accuracy: 0.87500 Validation accuracy: 0.75080\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.44569 Training accuracy: 0.87500 Validation accuracy: 0.74760\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.54600 Training accuracy: 0.82500 Validation accuracy: 0.75260\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.54709 Training accuracy: 0.85000 Validation accuracy: 0.75140\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.33344 Training accuracy: 0.90000 Validation accuracy: 0.74940\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.49726 Training accuracy: 0.87500 Validation accuracy: 0.74400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.44118 Training accuracy: 0.82500 Validation accuracy: 0.75060\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.53498 Training accuracy: 0.82500 Validation accuracy: 0.74640\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.53064 Training accuracy: 0.82500 Validation accuracy: 0.74660\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.33258 Training accuracy: 0.87500 Validation accuracy: 0.74240\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.49063 Training accuracy: 0.87500 Validation accuracy: 0.74560\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.42404 Training accuracy: 0.87500 Validation accuracy: 0.74540\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.57820 Training accuracy: 0.77500 Validation accuracy: 0.75280\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.57946 Training accuracy: 0.82500 Validation accuracy: 0.74140\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.31374 Training accuracy: 0.92500 Validation accuracy: 0.74740\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.42918 Training accuracy: 0.90000 Validation accuracy: 0.74520\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.40072 Training accuracy: 0.90000 Validation accuracy: 0.74140\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.55328 Training accuracy: 0.82500 Validation accuracy: 0.74400\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.55293 Training accuracy: 0.82500 Validation accuracy: 0.74400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.33454 Training accuracy: 0.90000 Validation accuracy: 0.74240\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.44278 Training accuracy: 0.90000 Validation accuracy: 0.75120\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.43942 Training accuracy: 0.90000 Validation accuracy: 0.74460\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.58364 Training accuracy: 0.77500 Validation accuracy: 0.74440\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.53338 Training accuracy: 0.82500 Validation accuracy: 0.75180\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.30696 Training accuracy: 0.95000 Validation accuracy: 0.75180\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.43775 Training accuracy: 0.90000 Validation accuracy: 0.74840\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.40955 Training accuracy: 0.90000 Validation accuracy: 0.74700\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.57228 Training accuracy: 0.80000 Validation accuracy: 0.75300\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.49879 Training accuracy: 0.90000 Validation accuracy: 0.75120\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.30468 Training accuracy: 0.92500 Validation accuracy: 0.74600\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.42720 Training accuracy: 0.87500 Validation accuracy: 0.75360\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.40123 Training accuracy: 0.90000 Validation accuracy: 0.74940\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.53933 Training accuracy: 0.77500 Validation accuracy: 0.74940\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.52982 Training accuracy: 0.87500 Validation accuracy: 0.74700\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.32787 Training accuracy: 0.92500 Validation accuracy: 0.74720\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.43015 Training accuracy: 0.90000 Validation accuracy: 0.74700\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.36791 Training accuracy: 0.95000 Validation accuracy: 0.74820\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.57052 Training accuracy: 0.75000 Validation accuracy: 0.74960\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.51835 Training accuracy: 0.90000 Validation accuracy: 0.74720\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.30788 Training accuracy: 0.90000 Validation accuracy: 0.74720\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.43811 Training accuracy: 0.87500 Validation accuracy: 0.75120\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.37809 Training accuracy: 0.92500 Validation accuracy: 0.74840\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.53870 Training accuracy: 0.77500 Validation accuracy: 0.75080\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.53005 Training accuracy: 0.80000 Validation accuracy: 0.73980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.28378 Training accuracy: 0.95000 Validation accuracy: 0.74240\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.43643 Training accuracy: 0.90000 Validation accuracy: 0.75040\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.35310 Training accuracy: 0.95000 Validation accuracy: 0.74740\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.55634 Training accuracy: 0.77500 Validation accuracy: 0.74760\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.44198 Training accuracy: 0.92500 Validation accuracy: 0.74880\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.31114 Training accuracy: 0.92500 Validation accuracy: 0.75060\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.42562 Training accuracy: 0.90000 Validation accuracy: 0.75200\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.36213 Training accuracy: 0.92500 Validation accuracy: 0.75260\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.51541 Training accuracy: 0.77500 Validation accuracy: 0.74540\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.45090 Training accuracy: 0.82500 Validation accuracy: 0.74540\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.31985 Training accuracy: 0.92500 Validation accuracy: 0.74980\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.40874 Training accuracy: 0.90000 Validation accuracy: 0.74740\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.37215 Training accuracy: 0.92500 Validation accuracy: 0.74440\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.53872 Training accuracy: 0.77500 Validation accuracy: 0.74840\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.51271 Training accuracy: 0.82500 Validation accuracy: 0.74840\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.32649 Training accuracy: 0.92500 Validation accuracy: 0.74940\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.44386 Training accuracy: 0.90000 Validation accuracy: 0.74940\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.38635 Training accuracy: 0.90000 Validation accuracy: 0.74940\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.53835 Training accuracy: 0.80000 Validation accuracy: 0.74820\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.50385 Training accuracy: 0.82500 Validation accuracy: 0.75460\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.32261 Training accuracy: 0.90000 Validation accuracy: 0.74480\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.41318 Training accuracy: 0.90000 Validation accuracy: 0.76060\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.37375 Training accuracy: 0.92500 Validation accuracy: 0.75140\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.52525 Training accuracy: 0.82500 Validation accuracy: 0.75060\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.50554 Training accuracy: 0.87500 Validation accuracy: 0.74340\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.32421 Training accuracy: 0.90000 Validation accuracy: 0.74000\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.41714 Training accuracy: 0.90000 Validation accuracy: 0.75420\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.37432 Training accuracy: 0.92500 Validation accuracy: 0.74960\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.49349 Training accuracy: 0.80000 Validation accuracy: 0.74620\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.48956 Training accuracy: 0.87500 Validation accuracy: 0.75100\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.31578 Training accuracy: 0.92500 Validation accuracy: 0.74760\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.41243 Training accuracy: 0.87500 Validation accuracy: 0.75120\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.37503 Training accuracy: 0.92500 Validation accuracy: 0.75180\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.50617 Training accuracy: 0.85000 Validation accuracy: 0.74600\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.47972 Training accuracy: 0.87500 Validation accuracy: 0.74500\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.31261 Training accuracy: 0.92500 Validation accuracy: 0.74760\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.41169 Training accuracy: 0.87500 Validation accuracy: 0.75760\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.36369 Training accuracy: 0.90000 Validation accuracy: 0.75340\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.48267 Training accuracy: 0.90000 Validation accuracy: 0.75380\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.49786 Training accuracy: 0.82500 Validation accuracy: 0.74480\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.26829 Training accuracy: 0.95000 Validation accuracy: 0.75280\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.41218 Training accuracy: 0.90000 Validation accuracy: 0.74760\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.34129 Training accuracy: 0.95000 Validation accuracy: 0.74840\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.47729 Training accuracy: 0.80000 Validation accuracy: 0.75420\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.51503 Training accuracy: 0.80000 Validation accuracy: 0.74800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.29759 Training accuracy: 0.95000 Validation accuracy: 0.75160\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.41954 Training accuracy: 0.87500 Validation accuracy: 0.75260\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.38577 Training accuracy: 0.90000 Validation accuracy: 0.74840\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.52275 Training accuracy: 0.82500 Validation accuracy: 0.75500\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.48564 Training accuracy: 0.85000 Validation accuracy: 0.75320\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.28253 Training accuracy: 0.92500 Validation accuracy: 0.75160\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.41489 Training accuracy: 0.90000 Validation accuracy: 0.75340\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.37182 Training accuracy: 0.90000 Validation accuracy: 0.75660\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.51715 Training accuracy: 0.80000 Validation accuracy: 0.75240\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.45229 Training accuracy: 0.85000 Validation accuracy: 0.75140\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.26310 Training accuracy: 0.95000 Validation accuracy: 0.75540\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.41193 Training accuracy: 0.87500 Validation accuracy: 0.75620\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.38270 Training accuracy: 0.92500 Validation accuracy: 0.75420\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.50398 Training accuracy: 0.80000 Validation accuracy: 0.74900\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.44990 Training accuracy: 0.87500 Validation accuracy: 0.74780\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.25815 Training accuracy: 0.92500 Validation accuracy: 0.75200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.40180 Training accuracy: 0.90000 Validation accuracy: 0.75200\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.41870 Training accuracy: 0.87500 Validation accuracy: 0.75200\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.51989 Training accuracy: 0.85000 Validation accuracy: 0.74780\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.48770 Training accuracy: 0.85000 Validation accuracy: 0.75760\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.27354 Training accuracy: 0.92500 Validation accuracy: 0.74280\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.40047 Training accuracy: 0.90000 Validation accuracy: 0.75300\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.39634 Training accuracy: 0.85000 Validation accuracy: 0.74980\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.55073 Training accuracy: 0.82500 Validation accuracy: 0.74800\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.41927 Training accuracy: 0.87500 Validation accuracy: 0.74620\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.28210 Training accuracy: 0.92500 Validation accuracy: 0.74380\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.38710 Training accuracy: 0.90000 Validation accuracy: 0.76340\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.37929 Training accuracy: 0.92500 Validation accuracy: 0.75720\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.51793 Training accuracy: 0.75000 Validation accuracy: 0.75560\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.42947 Training accuracy: 0.85000 Validation accuracy: 0.75940\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.28253 Training accuracy: 0.92500 Validation accuracy: 0.75080\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.41445 Training accuracy: 0.87500 Validation accuracy: 0.75820\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.36403 Training accuracy: 0.92500 Validation accuracy: 0.75700\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.51117 Training accuracy: 0.85000 Validation accuracy: 0.75380\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.50082 Training accuracy: 0.85000 Validation accuracy: 0.75580\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.28226 Training accuracy: 0.95000 Validation accuracy: 0.75720\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.37893 Training accuracy: 0.90000 Validation accuracy: 0.75820\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.42464 Training accuracy: 0.90000 Validation accuracy: 0.74980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.48490 Training accuracy: 0.87500 Validation accuracy: 0.75380\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.43653 Training accuracy: 0.90000 Validation accuracy: 0.74820\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.29447 Training accuracy: 0.90000 Validation accuracy: 0.75380\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.40008 Training accuracy: 0.87500 Validation accuracy: 0.75960\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.32323 Training accuracy: 0.95000 Validation accuracy: 0.75660\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.52482 Training accuracy: 0.80000 Validation accuracy: 0.74700\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.46494 Training accuracy: 0.90000 Validation accuracy: 0.75220\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.25371 Training accuracy: 0.92500 Validation accuracy: 0.75640\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.38798 Training accuracy: 0.90000 Validation accuracy: 0.75660\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.36504 Training accuracy: 0.95000 Validation accuracy: 0.75680\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.47043 Training accuracy: 0.85000 Validation accuracy: 0.75540\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.41705 Training accuracy: 0.95000 Validation accuracy: 0.75680\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.25769 Training accuracy: 0.92500 Validation accuracy: 0.75320\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.38375 Training accuracy: 0.87500 Validation accuracy: 0.76040\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.32158 Training accuracy: 0.95000 Validation accuracy: 0.75120\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.48825 Training accuracy: 0.82500 Validation accuracy: 0.75840\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.40727 Training accuracy: 0.90000 Validation accuracy: 0.75300\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.25968 Training accuracy: 0.92500 Validation accuracy: 0.75180\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.39972 Training accuracy: 0.90000 Validation accuracy: 0.75540\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.34968 Training accuracy: 0.92500 Validation accuracy: 0.75420\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.47563 Training accuracy: 0.82500 Validation accuracy: 0.76000\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.41039 Training accuracy: 0.92500 Validation accuracy: 0.75820\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.26567 Training accuracy: 0.95000 Validation accuracy: 0.75500\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.41555 Training accuracy: 0.87500 Validation accuracy: 0.75600\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.32106 Training accuracy: 0.97500 Validation accuracy: 0.75660\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.45043 Training accuracy: 0.82500 Validation accuracy: 0.75780\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.40020 Training accuracy: 0.90000 Validation accuracy: 0.76000\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.24486 Training accuracy: 0.95000 Validation accuracy: 0.75360\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.36496 Training accuracy: 0.92500 Validation accuracy: 0.75160\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.32105 Training accuracy: 0.95000 Validation accuracy: 0.75340\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.46398 Training accuracy: 0.85000 Validation accuracy: 0.75580\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.41141 Training accuracy: 0.87500 Validation accuracy: 0.75580\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.24974 Training accuracy: 0.95000 Validation accuracy: 0.75580\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.39360 Training accuracy: 0.92500 Validation accuracy: 0.74960\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.32262 Training accuracy: 0.92500 Validation accuracy: 0.75800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.48987 Training accuracy: 0.87500 Validation accuracy: 0.75200\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.44644 Training accuracy: 0.90000 Validation accuracy: 0.74780\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.28378 Training accuracy: 0.92500 Validation accuracy: 0.75140\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.38127 Training accuracy: 0.87500 Validation accuracy: 0.75000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.32358 Training accuracy: 0.92500 Validation accuracy: 0.76100\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.52087 Training accuracy: 0.80000 Validation accuracy: 0.74880\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.43298 Training accuracy: 0.87500 Validation accuracy: 0.75480\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.28649 Training accuracy: 0.95000 Validation accuracy: 0.75080\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.38363 Training accuracy: 0.90000 Validation accuracy: 0.75120\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.30921 Training accuracy: 0.97500 Validation accuracy: 0.75900\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.47074 Training accuracy: 0.87500 Validation accuracy: 0.75240\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.43056 Training accuracy: 0.87500 Validation accuracy: 0.75640\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.26409 Training accuracy: 0.92500 Validation accuracy: 0.74420\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.36948 Training accuracy: 0.92500 Validation accuracy: 0.75440\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.35671 Training accuracy: 0.90000 Validation accuracy: 0.75540\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.51244 Training accuracy: 0.87500 Validation accuracy: 0.75800\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.37069 Training accuracy: 0.92500 Validation accuracy: 0.75700\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.25444 Training accuracy: 0.95000 Validation accuracy: 0.75060\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.38503 Training accuracy: 0.92500 Validation accuracy: 0.75300\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.33230 Training accuracy: 0.95000 Validation accuracy: 0.75820\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.42071 Training accuracy: 0.90000 Validation accuracy: 0.75860\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 0.38812 Training accuracy: 0.90000 Validation accuracy: 0.75840\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.30755 Training accuracy: 0.87500 Validation accuracy: 0.75940\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.36660 Training accuracy: 0.92500 Validation accuracy: 0.76160\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.36408 Training accuracy: 0.90000 Validation accuracy: 0.75740\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.46988 Training accuracy: 0.85000 Validation accuracy: 0.75760\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.45906 Training accuracy: 0.87500 Validation accuracy: 0.74600\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.29295 Training accuracy: 0.90000 Validation accuracy: 0.75520\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.37542 Training accuracy: 0.92500 Validation accuracy: 0.76100\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.35450 Training accuracy: 0.92500 Validation accuracy: 0.76460\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.52112 Training accuracy: 0.77500 Validation accuracy: 0.74640\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.41971 Training accuracy: 0.95000 Validation accuracy: 0.76020\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.25962 Training accuracy: 0.95000 Validation accuracy: 0.75380\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.36312 Training accuracy: 0.90000 Validation accuracy: 0.75840\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.35867 Training accuracy: 0.92500 Validation accuracy: 0.75740\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.47839 Training accuracy: 0.87500 Validation accuracy: 0.75080\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.39903 Training accuracy: 0.90000 Validation accuracy: 0.76020\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.29085 Training accuracy: 0.87500 Validation accuracy: 0.75500\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.35799 Training accuracy: 0.90000 Validation accuracy: 0.76560\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.39226 Training accuracy: 0.92500 Validation accuracy: 0.75180\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.47169 Training accuracy: 0.82500 Validation accuracy: 0.75340\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.42569 Training accuracy: 0.92500 Validation accuracy: 0.75840\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.26860 Training accuracy: 0.92500 Validation accuracy: 0.75560\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.37513 Training accuracy: 0.90000 Validation accuracy: 0.75940\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.36233 Training accuracy: 0.92500 Validation accuracy: 0.75840\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.49241 Training accuracy: 0.80000 Validation accuracy: 0.75340\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.38166 Training accuracy: 0.90000 Validation accuracy: 0.76100\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.25967 Training accuracy: 0.95000 Validation accuracy: 0.76100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.36780 Training accuracy: 0.90000 Validation accuracy: 0.76660\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.31088 Training accuracy: 0.90000 Validation accuracy: 0.75820\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.45105 Training accuracy: 0.82500 Validation accuracy: 0.76180\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss: 0.35827 Training accuracy: 0.90000 Validation accuracy: 0.75600\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss: 0.25914 Training accuracy: 0.92500 Validation accuracy: 0.76200\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss: 0.39023 Training accuracy: 0.92500 Validation accuracy: 0.75340\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss: 0.32343 Training accuracy: 0.90000 Validation accuracy: 0.75860\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.43154 Training accuracy: 0.85000 Validation accuracy: 0.76160\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss: 0.41052 Training accuracy: 0.85000 Validation accuracy: 0.76260\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss: 0.25174 Training accuracy: 0.95000 Validation accuracy: 0.76620\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss: 0.38301 Training accuracy: 0.87500 Validation accuracy: 0.76380\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss: 0.32151 Training accuracy: 0.90000 Validation accuracy: 0.76400\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.46604 Training accuracy: 0.80000 Validation accuracy: 0.76000\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss: 0.41260 Training accuracy: 0.90000 Validation accuracy: 0.75820\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss: 0.25101 Training accuracy: 0.97500 Validation accuracy: 0.75780\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss: 0.38221 Training accuracy: 0.87500 Validation accuracy: 0.76100\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss: 0.33658 Training accuracy: 0.92500 Validation accuracy: 0.75920\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.44158 Training accuracy: 0.87500 Validation accuracy: 0.76320\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss: 0.39303 Training accuracy: 0.87500 Validation accuracy: 0.75980\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss: 0.26956 Training accuracy: 0.90000 Validation accuracy: 0.75600\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss: 0.35244 Training accuracy: 0.90000 Validation accuracy: 0.76320\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss: 0.34815 Training accuracy: 0.97500 Validation accuracy: 0.75880\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.44092 Training accuracy: 0.82500 Validation accuracy: 0.76140\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss: 0.37223 Training accuracy: 0.87500 Validation accuracy: 0.76660\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss: 0.24467 Training accuracy: 0.95000 Validation accuracy: 0.75300\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss: 0.33969 Training accuracy: 0.92500 Validation accuracy: 0.75780\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss: 0.33732 Training accuracy: 0.95000 Validation accuracy: 0.76200\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.43964 Training accuracy: 0.85000 Validation accuracy: 0.76040\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss: 0.41123 Training accuracy: 0.90000 Validation accuracy: 0.76320\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss: 0.28262 Training accuracy: 0.95000 Validation accuracy: 0.76600\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss: 0.34534 Training accuracy: 0.92500 Validation accuracy: 0.76040\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss: 0.33136 Training accuracy: 0.92500 Validation accuracy: 0.76660\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.46943 Training accuracy: 0.82500 Validation accuracy: 0.75700\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss: 0.40571 Training accuracy: 0.90000 Validation accuracy: 0.75600\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss: 0.24450 Training accuracy: 0.92500 Validation accuracy: 0.76200\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss: 0.34980 Training accuracy: 0.92500 Validation accuracy: 0.75900\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss: 0.33504 Training accuracy: 0.95000 Validation accuracy: 0.76360\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.43080 Training accuracy: 0.87500 Validation accuracy: 0.76160\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss: 0.35218 Training accuracy: 0.90000 Validation accuracy: 0.76340\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss: 0.22435 Training accuracy: 1.00000 Validation accuracy: 0.76460\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss: 0.35737 Training accuracy: 0.95000 Validation accuracy: 0.76280\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss: 0.34406 Training accuracy: 0.90000 Validation accuracy: 0.75620\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.49960 Training accuracy: 0.82500 Validation accuracy: 0.75800\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss: 0.38704 Training accuracy: 0.87500 Validation accuracy: 0.75740\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss: 0.23783 Training accuracy: 0.95000 Validation accuracy: 0.75480\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss: 0.36673 Training accuracy: 0.90000 Validation accuracy: 0.76220\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss: 0.33896 Training accuracy: 0.90000 Validation accuracy: 0.75920\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.44724 Training accuracy: 0.82500 Validation accuracy: 0.75960\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss: 0.40430 Training accuracy: 0.90000 Validation accuracy: 0.75460\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss: 0.24115 Training accuracy: 0.97500 Validation accuracy: 0.75800\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss: 0.35177 Training accuracy: 0.92500 Validation accuracy: 0.76600\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss: 0.29921 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.44165 Training accuracy: 0.85000 Validation accuracy: 0.75840\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss: 0.39941 Training accuracy: 0.90000 Validation accuracy: 0.75860\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss: 0.22839 Training accuracy: 0.95000 Validation accuracy: 0.75920\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss: 0.34691 Training accuracy: 0.95000 Validation accuracy: 0.76860\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss: 0.33740 Training accuracy: 0.95000 Validation accuracy: 0.76500\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.46075 Training accuracy: 0.85000 Validation accuracy: 0.75220\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss: 0.39014 Training accuracy: 0.90000 Validation accuracy: 0.75880\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss: 0.22161 Training accuracy: 1.00000 Validation accuracy: 0.76000\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss: 0.37046 Training accuracy: 0.92500 Validation accuracy: 0.75540\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss: 0.35140 Training accuracy: 0.92500 Validation accuracy: 0.76120\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.44144 Training accuracy: 0.85000 Validation accuracy: 0.75440\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss: 0.41261 Training accuracy: 0.90000 Validation accuracy: 0.76140\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss: 0.23494 Training accuracy: 0.95000 Validation accuracy: 0.75760\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss: 0.32074 Training accuracy: 0.92500 Validation accuracy: 0.76260\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss: 0.28435 Training accuracy: 0.97500 Validation accuracy: 0.76200\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.42097 Training accuracy: 0.85000 Validation accuracy: 0.75340\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss: 0.38626 Training accuracy: 0.87500 Validation accuracy: 0.75760\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss: 0.22358 Training accuracy: 0.95000 Validation accuracy: 0.76280\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss: 0.33421 Training accuracy: 0.92500 Validation accuracy: 0.76100\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss: 0.25956 Training accuracy: 0.97500 Validation accuracy: 0.76200\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.43451 Training accuracy: 0.85000 Validation accuracy: 0.75020\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss: 0.36897 Training accuracy: 0.92500 Validation accuracy: 0.76640\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss: 0.26007 Training accuracy: 0.95000 Validation accuracy: 0.76220\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss: 0.35347 Training accuracy: 0.90000 Validation accuracy: 0.76180\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss: 0.29281 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.45070 Training accuracy: 0.87500 Validation accuracy: 0.75980\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss: 0.40832 Training accuracy: 0.90000 Validation accuracy: 0.76000\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss: 0.22166 Training accuracy: 0.92500 Validation accuracy: 0.75820\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss: 0.33595 Training accuracy: 0.90000 Validation accuracy: 0.76780\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss: 0.31316 Training accuracy: 0.92500 Validation accuracy: 0.76720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.45649 Training accuracy: 0.80000 Validation accuracy: 0.75820\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss: 0.37608 Training accuracy: 0.90000 Validation accuracy: 0.76120\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss: 0.21358 Training accuracy: 0.97500 Validation accuracy: 0.76480\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss: 0.32226 Training accuracy: 0.90000 Validation accuracy: 0.76140\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss: 0.31711 Training accuracy: 0.95000 Validation accuracy: 0.75820\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.44730 Training accuracy: 0.82500 Validation accuracy: 0.76080\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss: 0.36038 Training accuracy: 0.92500 Validation accuracy: 0.76300\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss: 0.24283 Training accuracy: 0.92500 Validation accuracy: 0.76080\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss: 0.34081 Training accuracy: 0.92500 Validation accuracy: 0.76360\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss: 0.35124 Training accuracy: 0.95000 Validation accuracy: 0.76720\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.44304 Training accuracy: 0.85000 Validation accuracy: 0.75960\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss: 0.37608 Training accuracy: 0.92500 Validation accuracy: 0.76100\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss: 0.24807 Training accuracy: 0.95000 Validation accuracy: 0.76040\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss: 0.34876 Training accuracy: 0.95000 Validation accuracy: 0.76060\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss: 0.31063 Training accuracy: 0.95000 Validation accuracy: 0.76280\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.44851 Training accuracy: 0.82500 Validation accuracy: 0.76080\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss: 0.35294 Training accuracy: 0.92500 Validation accuracy: 0.75920\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss: 0.18420 Training accuracy: 0.97500 Validation accuracy: 0.75560\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss: 0.32457 Training accuracy: 0.95000 Validation accuracy: 0.76260\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss: 0.28349 Training accuracy: 0.95000 Validation accuracy: 0.76120\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.46122 Training accuracy: 0.82500 Validation accuracy: 0.76220\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss: 0.34856 Training accuracy: 0.92500 Validation accuracy: 0.75940\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss: 0.20977 Training accuracy: 0.97500 Validation accuracy: 0.76340\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss: 0.34769 Training accuracy: 0.95000 Validation accuracy: 0.76480\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss: 0.28699 Training accuracy: 0.97500 Validation accuracy: 0.76380\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.46496 Training accuracy: 0.80000 Validation accuracy: 0.76660\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss: 0.40019 Training accuracy: 0.90000 Validation accuracy: 0.75960\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss: 0.20288 Training accuracy: 0.92500 Validation accuracy: 0.75740\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss: 0.33890 Training accuracy: 0.95000 Validation accuracy: 0.76080\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss: 0.33008 Training accuracy: 0.92500 Validation accuracy: 0.76780\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.44644 Training accuracy: 0.85000 Validation accuracy: 0.77000\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss: 0.38085 Training accuracy: 0.85000 Validation accuracy: 0.76360\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss: 0.21890 Training accuracy: 1.00000 Validation accuracy: 0.76180\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss: 0.32935 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss: 0.32587 Training accuracy: 0.95000 Validation accuracy: 0.76700\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.42644 Training accuracy: 0.87500 Validation accuracy: 0.75940\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss: 0.36772 Training accuracy: 0.92500 Validation accuracy: 0.75980\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss: 0.20401 Training accuracy: 1.00000 Validation accuracy: 0.76260\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss: 0.34995 Training accuracy: 0.95000 Validation accuracy: 0.75940\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss: 0.29565 Training accuracy: 0.97500 Validation accuracy: 0.76540\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.42386 Training accuracy: 0.85000 Validation accuracy: 0.76380\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss: 0.36662 Training accuracy: 0.90000 Validation accuracy: 0.75760\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss: 0.21825 Training accuracy: 1.00000 Validation accuracy: 0.75400\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss: 0.31636 Training accuracy: 0.95000 Validation accuracy: 0.75960\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss: 0.30971 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.40611 Training accuracy: 0.85000 Validation accuracy: 0.76500\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss: 0.35025 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss: 0.20894 Training accuracy: 1.00000 Validation accuracy: 0.76460\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss: 0.32691 Training accuracy: 0.95000 Validation accuracy: 0.75720\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss: 0.27546 Training accuracy: 1.00000 Validation accuracy: 0.77000\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.42176 Training accuracy: 0.82500 Validation accuracy: 0.76380\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss: 0.31836 Training accuracy: 0.92500 Validation accuracy: 0.76860\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss: 0.19054 Training accuracy: 1.00000 Validation accuracy: 0.76080\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss: 0.33535 Training accuracy: 0.92500 Validation accuracy: 0.76720\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss: 0.33226 Training accuracy: 0.92500 Validation accuracy: 0.76580\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.42260 Training accuracy: 0.90000 Validation accuracy: 0.76380\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss: 0.31929 Training accuracy: 0.95000 Validation accuracy: 0.76100\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss: 0.21702 Training accuracy: 0.95000 Validation accuracy: 0.76200\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss: 0.33568 Training accuracy: 0.90000 Validation accuracy: 0.76740\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss: 0.26391 Training accuracy: 0.95000 Validation accuracy: 0.76480\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.41367 Training accuracy: 0.85000 Validation accuracy: 0.76240\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss: 0.36043 Training accuracy: 0.95000 Validation accuracy: 0.76420\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss: 0.20315 Training accuracy: 0.97500 Validation accuracy: 0.76360\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss: 0.30826 Training accuracy: 0.95000 Validation accuracy: 0.76560\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss: 0.26347 Training accuracy: 0.97500 Validation accuracy: 0.76660\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.42341 Training accuracy: 0.87500 Validation accuracy: 0.76080\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss: 0.33482 Training accuracy: 0.95000 Validation accuracy: 0.76100\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss: 0.19994 Training accuracy: 0.95000 Validation accuracy: 0.75580\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss: 0.33907 Training accuracy: 0.95000 Validation accuracy: 0.76200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss: 0.27486 Training accuracy: 0.95000 Validation accuracy: 0.76440\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.41608 Training accuracy: 0.90000 Validation accuracy: 0.76140\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss: 0.34704 Training accuracy: 0.90000 Validation accuracy: 0.75940\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss: 0.21137 Training accuracy: 1.00000 Validation accuracy: 0.76260\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss: 0.33261 Training accuracy: 0.92500 Validation accuracy: 0.76360\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss: 0.29367 Training accuracy: 0.97500 Validation accuracy: 0.76320\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.40426 Training accuracy: 0.87500 Validation accuracy: 0.76120\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss: 0.33126 Training accuracy: 0.92500 Validation accuracy: 0.76320\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss: 0.19899 Training accuracy: 1.00000 Validation accuracy: 0.76180\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss: 0.33483 Training accuracy: 0.92500 Validation accuracy: 0.76420\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss: 0.30781 Training accuracy: 0.95000 Validation accuracy: 0.76520\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.38591 Training accuracy: 0.92500 Validation accuracy: 0.75940\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss: 0.35145 Training accuracy: 0.92500 Validation accuracy: 0.75820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133, CIFAR-10 Batch 3:  Loss: 0.20426 Training accuracy: 0.97500 Validation accuracy: 0.76300\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss: 0.32395 Training accuracy: 0.92500 Validation accuracy: 0.76520\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss: 0.31375 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.47347 Training accuracy: 0.87500 Validation accuracy: 0.76580\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss: 0.34160 Training accuracy: 0.92500 Validation accuracy: 0.75980\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss: 0.21312 Training accuracy: 1.00000 Validation accuracy: 0.76300\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss: 0.33084 Training accuracy: 0.92500 Validation accuracy: 0.76440\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss: 0.32056 Training accuracy: 0.92500 Validation accuracy: 0.76440\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.41348 Training accuracy: 0.85000 Validation accuracy: 0.76180\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss: 0.32644 Training accuracy: 0.92500 Validation accuracy: 0.75600\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss: 0.21011 Training accuracy: 0.95000 Validation accuracy: 0.76120\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss: 0.34008 Training accuracy: 0.95000 Validation accuracy: 0.76200\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss: 0.28104 Training accuracy: 0.95000 Validation accuracy: 0.76480\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.40487 Training accuracy: 0.87500 Validation accuracy: 0.76360\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss: 0.34326 Training accuracy: 0.90000 Validation accuracy: 0.76180\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss: 0.23020 Training accuracy: 0.95000 Validation accuracy: 0.76700\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss: 0.34131 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss: 0.26962 Training accuracy: 0.97500 Validation accuracy: 0.75980\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.44169 Training accuracy: 0.87500 Validation accuracy: 0.76460\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss: 0.37830 Training accuracy: 0.90000 Validation accuracy: 0.76340\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss: 0.19928 Training accuracy: 1.00000 Validation accuracy: 0.76360\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss: 0.32492 Training accuracy: 0.92500 Validation accuracy: 0.76780\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss: 0.25865 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.44824 Training accuracy: 0.85000 Validation accuracy: 0.76240\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss: 0.33131 Training accuracy: 0.87500 Validation accuracy: 0.76240\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss: 0.22110 Training accuracy: 0.97500 Validation accuracy: 0.76880\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss: 0.30985 Training accuracy: 0.92500 Validation accuracy: 0.76780\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss: 0.28096 Training accuracy: 0.97500 Validation accuracy: 0.76560\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.40426 Training accuracy: 0.92500 Validation accuracy: 0.75920\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss: 0.36159 Training accuracy: 0.92500 Validation accuracy: 0.76160\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss: 0.22026 Training accuracy: 1.00000 Validation accuracy: 0.76820\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss: 0.32160 Training accuracy: 0.92500 Validation accuracy: 0.75940\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss: 0.25601 Training accuracy: 0.97500 Validation accuracy: 0.76700\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.43712 Training accuracy: 0.87500 Validation accuracy: 0.76620\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss: 0.36799 Training accuracy: 0.90000 Validation accuracy: 0.75500\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss: 0.21770 Training accuracy: 1.00000 Validation accuracy: 0.76520\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss: 0.31967 Training accuracy: 0.90000 Validation accuracy: 0.76540\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss: 0.27330 Training accuracy: 0.97500 Validation accuracy: 0.76920\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.45512 Training accuracy: 0.87500 Validation accuracy: 0.75400\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss: 0.35097 Training accuracy: 0.92500 Validation accuracy: 0.76220\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss: 0.23697 Training accuracy: 0.97500 Validation accuracy: 0.76360\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss: 0.32675 Training accuracy: 0.90000 Validation accuracy: 0.76220\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss: 0.27754 Training accuracy: 0.97500 Validation accuracy: 0.75880\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.44816 Training accuracy: 0.85000 Validation accuracy: 0.76260\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss: 0.32311 Training accuracy: 0.92500 Validation accuracy: 0.76560\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss: 0.21028 Training accuracy: 0.95000 Validation accuracy: 0.76000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss: 0.34642 Training accuracy: 0.92500 Validation accuracy: 0.76460\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss: 0.24785 Training accuracy: 0.95000 Validation accuracy: 0.76440\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.43271 Training accuracy: 0.90000 Validation accuracy: 0.76220\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss: 0.38951 Training accuracy: 0.92500 Validation accuracy: 0.76520\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss: 0.21235 Training accuracy: 0.95000 Validation accuracy: 0.76160\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss: 0.30483 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss: 0.28671 Training accuracy: 0.92500 Validation accuracy: 0.76540\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.41297 Training accuracy: 0.92500 Validation accuracy: 0.76440\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss: 0.30719 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss: 0.21700 Training accuracy: 0.95000 Validation accuracy: 0.76140\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss: 0.29029 Training accuracy: 0.95000 Validation accuracy: 0.76360\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss: 0.25366 Training accuracy: 0.97500 Validation accuracy: 0.76760\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.40949 Training accuracy: 0.87500 Validation accuracy: 0.76040\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss: 0.33366 Training accuracy: 0.90000 Validation accuracy: 0.75660\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss: 0.21020 Training accuracy: 0.97500 Validation accuracy: 0.76780\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss: 0.32174 Training accuracy: 0.95000 Validation accuracy: 0.76000\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss: 0.27152 Training accuracy: 0.97500 Validation accuracy: 0.76520\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.42440 Training accuracy: 0.90000 Validation accuracy: 0.76800\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss: 0.30652 Training accuracy: 0.95000 Validation accuracy: 0.75840\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss: 0.22068 Training accuracy: 0.95000 Validation accuracy: 0.75680\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss: 0.29561 Training accuracy: 0.95000 Validation accuracy: 0.76500\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss: 0.24927 Training accuracy: 0.97500 Validation accuracy: 0.76540\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.45283 Training accuracy: 0.85000 Validation accuracy: 0.75500\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss: 0.31699 Training accuracy: 0.92500 Validation accuracy: 0.75660\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss: 0.22233 Training accuracy: 0.95000 Validation accuracy: 0.76480\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss: 0.32772 Training accuracy: 0.92500 Validation accuracy: 0.76660\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss: 0.25907 Training accuracy: 0.97500 Validation accuracy: 0.77040\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.40056 Training accuracy: 0.90000 Validation accuracy: 0.76600\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss: 0.32742 Training accuracy: 0.95000 Validation accuracy: 0.75760\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss: 0.18143 Training accuracy: 1.00000 Validation accuracy: 0.76680\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss: 0.29621 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss: 0.27313 Training accuracy: 0.97500 Validation accuracy: 0.76680\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.41059 Training accuracy: 0.87500 Validation accuracy: 0.75800\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss: 0.32948 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss: 0.21947 Training accuracy: 0.97500 Validation accuracy: 0.76400\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss: 0.30065 Training accuracy: 0.95000 Validation accuracy: 0.76300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149, CIFAR-10 Batch 5:  Loss: 0.29432 Training accuracy: 0.95000 Validation accuracy: 0.76580\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.38466 Training accuracy: 0.90000 Validation accuracy: 0.75860\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss: 0.33607 Training accuracy: 0.87500 Validation accuracy: 0.76140\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss: 0.19852 Training accuracy: 1.00000 Validation accuracy: 0.76920\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss: 0.31438 Training accuracy: 0.95000 Validation accuracy: 0.75760\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss: 0.29055 Training accuracy: 0.95000 Validation accuracy: 0.76320\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.36572 Training accuracy: 0.95000 Validation accuracy: 0.76620\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss: 0.32914 Training accuracy: 0.95000 Validation accuracy: 0.76600\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss: 0.21719 Training accuracy: 1.00000 Validation accuracy: 0.76900\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss: 0.31035 Training accuracy: 0.95000 Validation accuracy: 0.76620\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss: 0.25872 Training accuracy: 0.95000 Validation accuracy: 0.76600\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.39700 Training accuracy: 0.90000 Validation accuracy: 0.76240\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss: 0.29396 Training accuracy: 0.95000 Validation accuracy: 0.77020\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss: 0.21437 Training accuracy: 0.95000 Validation accuracy: 0.76700\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss: 0.29560 Training accuracy: 0.92500 Validation accuracy: 0.76620\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss: 0.26859 Training accuracy: 1.00000 Validation accuracy: 0.75920\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.34664 Training accuracy: 0.92500 Validation accuracy: 0.76340\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss: 0.27653 Training accuracy: 0.97500 Validation accuracy: 0.76080\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss: 0.22485 Training accuracy: 1.00000 Validation accuracy: 0.76720\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss: 0.30875 Training accuracy: 0.95000 Validation accuracy: 0.77280\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss: 0.24898 Training accuracy: 1.00000 Validation accuracy: 0.76400\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.38762 Training accuracy: 0.90000 Validation accuracy: 0.76060\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss: 0.32023 Training accuracy: 0.92500 Validation accuracy: 0.76100\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss: 0.22091 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss: 0.30804 Training accuracy: 0.92500 Validation accuracy: 0.77120\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss: 0.27999 Training accuracy: 0.95000 Validation accuracy: 0.76040\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.44821 Training accuracy: 0.87500 Validation accuracy: 0.75940\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss: 0.28387 Training accuracy: 0.95000 Validation accuracy: 0.76480\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss: 0.21597 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss: 0.30472 Training accuracy: 0.95000 Validation accuracy: 0.76800\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss: 0.25402 Training accuracy: 0.97500 Validation accuracy: 0.76760\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.40727 Training accuracy: 0.87500 Validation accuracy: 0.75880\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss: 0.32297 Training accuracy: 0.92500 Validation accuracy: 0.76400\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss: 0.21613 Training accuracy: 1.00000 Validation accuracy: 0.76800\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss: 0.32116 Training accuracy: 0.95000 Validation accuracy: 0.76860\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss: 0.24102 Training accuracy: 0.97500 Validation accuracy: 0.77000\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.41603 Training accuracy: 0.87500 Validation accuracy: 0.76800\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss: 0.31374 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss: 0.20595 Training accuracy: 1.00000 Validation accuracy: 0.76600\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss: 0.32917 Training accuracy: 0.95000 Validation accuracy: 0.76740\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss: 0.24987 Training accuracy: 1.00000 Validation accuracy: 0.76680\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.37385 Training accuracy: 0.87500 Validation accuracy: 0.76560\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss: 0.29266 Training accuracy: 0.95000 Validation accuracy: 0.76260\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss: 0.20514 Training accuracy: 0.95000 Validation accuracy: 0.76080\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss: 0.31623 Training accuracy: 0.92500 Validation accuracy: 0.76540\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss: 0.26883 Training accuracy: 0.97500 Validation accuracy: 0.76840\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.38971 Training accuracy: 0.92500 Validation accuracy: 0.75920\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss: 0.29059 Training accuracy: 0.95000 Validation accuracy: 0.76440\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss: 0.21672 Training accuracy: 0.97500 Validation accuracy: 0.76020\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss: 0.30625 Training accuracy: 0.95000 Validation accuracy: 0.77100\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss: 0.28679 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.34870 Training accuracy: 0.90000 Validation accuracy: 0.76420\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss: 0.28856 Training accuracy: 0.92500 Validation accuracy: 0.75560\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss: 0.21296 Training accuracy: 0.97500 Validation accuracy: 0.76320\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 0.29905 Training accuracy: 0.95000 Validation accuracy: 0.76560\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss: 0.28550 Training accuracy: 0.95000 Validation accuracy: 0.76740\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.39829 Training accuracy: 0.85000 Validation accuracy: 0.76620\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss: 0.31697 Training accuracy: 0.92500 Validation accuracy: 0.76760\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss: 0.20458 Training accuracy: 1.00000 Validation accuracy: 0.77000\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss: 0.28604 Training accuracy: 0.97500 Validation accuracy: 0.77020\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss: 0.29672 Training accuracy: 0.95000 Validation accuracy: 0.76880\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.41021 Training accuracy: 0.90000 Validation accuracy: 0.76660\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss: 0.34659 Training accuracy: 0.90000 Validation accuracy: 0.77340\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss: 0.20917 Training accuracy: 0.95000 Validation accuracy: 0.76960\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss: 0.31132 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss: 0.29007 Training accuracy: 0.92500 Validation accuracy: 0.77020\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.39345 Training accuracy: 0.87500 Validation accuracy: 0.76600\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss: 0.35882 Training accuracy: 0.92500 Validation accuracy: 0.77120\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss: 0.20150 Training accuracy: 0.97500 Validation accuracy: 0.76920\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss: 0.31261 Training accuracy: 0.95000 Validation accuracy: 0.77120\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss: 0.27912 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.34327 Training accuracy: 0.90000 Validation accuracy: 0.76300\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss: 0.32434 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss: 0.20888 Training accuracy: 1.00000 Validation accuracy: 0.76520\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss: 0.29819 Training accuracy: 0.95000 Validation accuracy: 0.76560\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss: 0.26534 Training accuracy: 1.00000 Validation accuracy: 0.76720\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.34413 Training accuracy: 0.92500 Validation accuracy: 0.76120\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss: 0.28710 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss: 0.21518 Training accuracy: 1.00000 Validation accuracy: 0.76940\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss: 0.28472 Training accuracy: 0.92500 Validation accuracy: 0.76920\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss: 0.26159 Training accuracy: 0.95000 Validation accuracy: 0.76860\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.35973 Training accuracy: 0.87500 Validation accuracy: 0.76220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166, CIFAR-10 Batch 2:  Loss: 0.32130 Training accuracy: 0.92500 Validation accuracy: 0.76820\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss: 0.24758 Training accuracy: 0.97500 Validation accuracy: 0.76920\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss: 0.33677 Training accuracy: 0.95000 Validation accuracy: 0.76420\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss: 0.26017 Training accuracy: 1.00000 Validation accuracy: 0.76640\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.38196 Training accuracy: 0.82500 Validation accuracy: 0.77140\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss: 0.33428 Training accuracy: 0.95000 Validation accuracy: 0.77400\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss: 0.18962 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss: 0.30705 Training accuracy: 0.95000 Validation accuracy: 0.77200\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss: 0.22114 Training accuracy: 1.00000 Validation accuracy: 0.77300\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.39388 Training accuracy: 0.87500 Validation accuracy: 0.76760\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss: 0.33142 Training accuracy: 0.95000 Validation accuracy: 0.77040\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss: 0.19150 Training accuracy: 0.95000 Validation accuracy: 0.76560\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss: 0.27744 Training accuracy: 0.95000 Validation accuracy: 0.77520\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss: 0.23167 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.38496 Training accuracy: 0.90000 Validation accuracy: 0.76700\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss: 0.30118 Training accuracy: 0.92500 Validation accuracy: 0.75600\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss: 0.21204 Training accuracy: 0.97500 Validation accuracy: 0.76560\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss: 0.30252 Training accuracy: 0.92500 Validation accuracy: 0.76940\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss: 0.24854 Training accuracy: 0.97500 Validation accuracy: 0.77060\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.38245 Training accuracy: 0.95000 Validation accuracy: 0.75940\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss: 0.31657 Training accuracy: 0.87500 Validation accuracy: 0.77280\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss: 0.20940 Training accuracy: 0.97500 Validation accuracy: 0.76640\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss: 0.34351 Training accuracy: 0.92500 Validation accuracy: 0.76620\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss: 0.22795 Training accuracy: 1.00000 Validation accuracy: 0.77100\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.36834 Training accuracy: 0.92500 Validation accuracy: 0.77140\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss: 0.32813 Training accuracy: 0.92500 Validation accuracy: 0.76400\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss: 0.19908 Training accuracy: 0.97500 Validation accuracy: 0.76980\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss: 0.32465 Training accuracy: 0.92500 Validation accuracy: 0.76520\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss: 0.25522 Training accuracy: 1.00000 Validation accuracy: 0.76140\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.36395 Training accuracy: 0.87500 Validation accuracy: 0.76100\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss: 0.30044 Training accuracy: 0.95000 Validation accuracy: 0.76620\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss: 0.18480 Training accuracy: 1.00000 Validation accuracy: 0.76300\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss: 0.33661 Training accuracy: 0.95000 Validation accuracy: 0.76580\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss: 0.25080 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.37848 Training accuracy: 0.87500 Validation accuracy: 0.77000\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss: 0.31658 Training accuracy: 0.92500 Validation accuracy: 0.76860\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss: 0.22845 Training accuracy: 0.92500 Validation accuracy: 0.76920\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss: 0.30746 Training accuracy: 0.95000 Validation accuracy: 0.76760\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss: 0.29625 Training accuracy: 0.97500 Validation accuracy: 0.76560\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.37029 Training accuracy: 0.92500 Validation accuracy: 0.76920\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss: 0.28938 Training accuracy: 0.95000 Validation accuracy: 0.76720\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss: 0.22193 Training accuracy: 0.95000 Validation accuracy: 0.76400\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss: 0.27496 Training accuracy: 0.95000 Validation accuracy: 0.76700\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss: 0.26895 Training accuracy: 0.95000 Validation accuracy: 0.76260\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.36957 Training accuracy: 0.87500 Validation accuracy: 0.75680\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss: 0.27647 Training accuracy: 0.97500 Validation accuracy: 0.76940\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss: 0.19481 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss: 0.30113 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss: 0.22084 Training accuracy: 1.00000 Validation accuracy: 0.77060\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.40066 Training accuracy: 0.87500 Validation accuracy: 0.76880\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss: 0.29065 Training accuracy: 0.97500 Validation accuracy: 0.76160\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss: 0.22411 Training accuracy: 0.97500 Validation accuracy: 0.76000\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss: 0.28529 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss: 0.23238 Training accuracy: 1.00000 Validation accuracy: 0.76600\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.36678 Training accuracy: 0.87500 Validation accuracy: 0.77220\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss: 0.28225 Training accuracy: 0.92500 Validation accuracy: 0.77160\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss: 0.19568 Training accuracy: 0.97500 Validation accuracy: 0.76460\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss: 0.28998 Training accuracy: 0.95000 Validation accuracy: 0.77200\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss: 0.27103 Training accuracy: 0.95000 Validation accuracy: 0.77020\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.39541 Training accuracy: 0.87500 Validation accuracy: 0.76060\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss: 0.30876 Training accuracy: 0.90000 Validation accuracy: 0.76200\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss: 0.18335 Training accuracy: 0.95000 Validation accuracy: 0.75520\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss: 0.29119 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss: 0.23697 Training accuracy: 1.00000 Validation accuracy: 0.77040\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.35110 Training accuracy: 0.92500 Validation accuracy: 0.75980\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss: 0.30637 Training accuracy: 0.92500 Validation accuracy: 0.76480\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss: 0.21965 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss: 0.28725 Training accuracy: 0.95000 Validation accuracy: 0.76800\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss: 0.26220 Training accuracy: 0.97500 Validation accuracy: 0.76300\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.34570 Training accuracy: 0.95000 Validation accuracy: 0.76440\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss: 0.27513 Training accuracy: 0.97500 Validation accuracy: 0.77060\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss: 0.18413 Training accuracy: 1.00000 Validation accuracy: 0.76560\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss: 0.31531 Training accuracy: 0.95000 Validation accuracy: 0.77180\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss: 0.22011 Training accuracy: 1.00000 Validation accuracy: 0.77580\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.37766 Training accuracy: 0.82500 Validation accuracy: 0.75960\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss: 0.26764 Training accuracy: 0.95000 Validation accuracy: 0.76180\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss: 0.18174 Training accuracy: 1.00000 Validation accuracy: 0.77160\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss: 0.29036 Training accuracy: 0.95000 Validation accuracy: 0.77580\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss: 0.25989 Training accuracy: 0.95000 Validation accuracy: 0.76920\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.37364 Training accuracy: 0.87500 Validation accuracy: 0.76140\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss: 0.27465 Training accuracy: 0.97500 Validation accuracy: 0.77220\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss: 0.18615 Training accuracy: 0.97500 Validation accuracy: 0.76160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182, CIFAR-10 Batch 4:  Loss: 0.30768 Training accuracy: 0.90000 Validation accuracy: 0.77140\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss: 0.22525 Training accuracy: 0.97500 Validation accuracy: 0.76800\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.32594 Training accuracy: 0.90000 Validation accuracy: 0.76620\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss: 0.31617 Training accuracy: 0.95000 Validation accuracy: 0.77180\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss: 0.19550 Training accuracy: 0.92500 Validation accuracy: 0.76040\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss: 0.32871 Training accuracy: 0.92500 Validation accuracy: 0.76800\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss: 0.25164 Training accuracy: 0.95000 Validation accuracy: 0.76960\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.33769 Training accuracy: 0.92500 Validation accuracy: 0.76860\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss: 0.25758 Training accuracy: 0.97500 Validation accuracy: 0.76940\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss: 0.18839 Training accuracy: 0.97500 Validation accuracy: 0.77180\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss: 0.26791 Training accuracy: 0.97500 Validation accuracy: 0.77140\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss: 0.22351 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.31166 Training accuracy: 0.92500 Validation accuracy: 0.76540\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss: 0.26471 Training accuracy: 0.95000 Validation accuracy: 0.77160\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss: 0.21333 Training accuracy: 0.97500 Validation accuracy: 0.76180\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss: 0.31123 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss: 0.24104 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.34202 Training accuracy: 0.87500 Validation accuracy: 0.76760\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss: 0.28822 Training accuracy: 0.92500 Validation accuracy: 0.76460\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss: 0.19690 Training accuracy: 0.97500 Validation accuracy: 0.75860\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss: 0.30277 Training accuracy: 0.95000 Validation accuracy: 0.76700\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss: 0.21265 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.38461 Training accuracy: 0.87500 Validation accuracy: 0.76560\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss: 0.30068 Training accuracy: 0.92500 Validation accuracy: 0.76540\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss: 0.21051 Training accuracy: 1.00000 Validation accuracy: 0.77380\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss: 0.28784 Training accuracy: 0.95000 Validation accuracy: 0.77220\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss: 0.21339 Training accuracy: 1.00000 Validation accuracy: 0.77000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.34570 Training accuracy: 0.92500 Validation accuracy: 0.76560\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss: 0.28207 Training accuracy: 0.92500 Validation accuracy: 0.77120\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss: 0.17892 Training accuracy: 1.00000 Validation accuracy: 0.76680\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss: 0.27981 Training accuracy: 0.95000 Validation accuracy: 0.77020\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss: 0.23985 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.36278 Training accuracy: 0.92500 Validation accuracy: 0.76540\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss: 0.30869 Training accuracy: 0.95000 Validation accuracy: 0.77120\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss: 0.19876 Training accuracy: 0.97500 Validation accuracy: 0.77380\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss: 0.28146 Training accuracy: 0.97500 Validation accuracy: 0.77140\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss: 0.22232 Training accuracy: 0.97500 Validation accuracy: 0.76760\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.34577 Training accuracy: 0.87500 Validation accuracy: 0.76260\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss: 0.26613 Training accuracy: 0.97500 Validation accuracy: 0.76900\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss: 0.16902 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss: 0.28089 Training accuracy: 0.97500 Validation accuracy: 0.77220\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss: 0.23551 Training accuracy: 0.97500 Validation accuracy: 0.77700\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.35480 Training accuracy: 0.92500 Validation accuracy: 0.76340\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss: 0.27446 Training accuracy: 0.97500 Validation accuracy: 0.76620\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss: 0.17668 Training accuracy: 1.00000 Validation accuracy: 0.76680\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss: 0.31023 Training accuracy: 0.97500 Validation accuracy: 0.77040\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss: 0.22726 Training accuracy: 0.97500 Validation accuracy: 0.77160\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.37173 Training accuracy: 0.95000 Validation accuracy: 0.76720\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss: 0.25444 Training accuracy: 0.95000 Validation accuracy: 0.76720\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss: 0.18633 Training accuracy: 0.92500 Validation accuracy: 0.75940\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss: 0.31622 Training accuracy: 0.95000 Validation accuracy: 0.77280\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss: 0.20015 Training accuracy: 1.00000 Validation accuracy: 0.77040\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.34706 Training accuracy: 0.90000 Validation accuracy: 0.77480\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss: 0.26464 Training accuracy: 0.95000 Validation accuracy: 0.76620\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss: 0.17294 Training accuracy: 1.00000 Validation accuracy: 0.77160\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss: 0.30660 Training accuracy: 0.95000 Validation accuracy: 0.76860\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss: 0.23501 Training accuracy: 0.95000 Validation accuracy: 0.77400\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.30618 Training accuracy: 0.95000 Validation accuracy: 0.76800\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss: 0.31169 Training accuracy: 0.92500 Validation accuracy: 0.76120\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss: 0.19958 Training accuracy: 1.00000 Validation accuracy: 0.76740\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss: 0.29302 Training accuracy: 0.97500 Validation accuracy: 0.77460\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss: 0.22698 Training accuracy: 0.97500 Validation accuracy: 0.77240\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.33202 Training accuracy: 0.92500 Validation accuracy: 0.77220\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss: 0.29765 Training accuracy: 0.90000 Validation accuracy: 0.76960\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss: 0.17446 Training accuracy: 1.00000 Validation accuracy: 0.76720\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss: 0.31056 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss: 0.21213 Training accuracy: 1.00000 Validation accuracy: 0.77120\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.32685 Training accuracy: 0.90000 Validation accuracy: 0.76920\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss: 0.25598 Training accuracy: 0.97500 Validation accuracy: 0.77020\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss: 0.16903 Training accuracy: 1.00000 Validation accuracy: 0.76740\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss: 0.29073 Training accuracy: 0.97500 Validation accuracy: 0.77520\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss: 0.23676 Training accuracy: 0.97500 Validation accuracy: 0.76980\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.36441 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss: 0.30901 Training accuracy: 0.92500 Validation accuracy: 0.76840\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss: 0.20219 Training accuracy: 0.97500 Validation accuracy: 0.77560\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss: 0.31929 Training accuracy: 0.92500 Validation accuracy: 0.77240\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss: 0.22213 Training accuracy: 1.00000 Validation accuracy: 0.77200\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.38532 Training accuracy: 0.87500 Validation accuracy: 0.76560\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss: 0.27245 Training accuracy: 0.97500 Validation accuracy: 0.76360\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss: 0.20885 Training accuracy: 1.00000 Validation accuracy: 0.76480\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss: 0.30925 Training accuracy: 0.95000 Validation accuracy: 0.77100\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss: 0.21473 Training accuracy: 1.00000 Validation accuracy: 0.77460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.36079 Training accuracy: 0.85000 Validation accuracy: 0.77320\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss: 0.27484 Training accuracy: 0.97500 Validation accuracy: 0.76520\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss: 0.19016 Training accuracy: 0.97500 Validation accuracy: 0.76980\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss: 0.32726 Training accuracy: 0.95000 Validation accuracy: 0.76580\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss: 0.22347 Training accuracy: 0.97500 Validation accuracy: 0.76920\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.39737 Training accuracy: 0.87500 Validation accuracy: 0.76820\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss: 0.25354 Training accuracy: 0.95000 Validation accuracy: 0.77400\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss: 0.18159 Training accuracy: 0.95000 Validation accuracy: 0.76300\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.28092 Training accuracy: 0.97500 Validation accuracy: 0.76840\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss: 0.20613 Training accuracy: 0.97500 Validation accuracy: 0.77100\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.35205 Training accuracy: 0.92500 Validation accuracy: 0.76180\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss: 0.28312 Training accuracy: 0.92500 Validation accuracy: 0.76040\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss: 0.19057 Training accuracy: 1.00000 Validation accuracy: 0.76920\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss: 0.29932 Training accuracy: 0.95000 Validation accuracy: 0.77000\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss: 0.24804 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.32379 Training accuracy: 0.95000 Validation accuracy: 0.75860\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss: 0.26429 Training accuracy: 0.97500 Validation accuracy: 0.76800\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss: 0.16474 Training accuracy: 0.97500 Validation accuracy: 0.76760\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss: 0.29873 Training accuracy: 0.92500 Validation accuracy: 0.76580\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss: 0.22853 Training accuracy: 0.97500 Validation accuracy: 0.77400\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.33587 Training accuracy: 0.90000 Validation accuracy: 0.76200\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss: 0.31612 Training accuracy: 0.92500 Validation accuracy: 0.76460\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss: 0.19277 Training accuracy: 0.97500 Validation accuracy: 0.76740\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss: 0.29601 Training accuracy: 0.95000 Validation accuracy: 0.76660\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss: 0.22215 Training accuracy: 0.95000 Validation accuracy: 0.77060\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.37055 Training accuracy: 0.90000 Validation accuracy: 0.76780\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss: 0.30865 Training accuracy: 0.90000 Validation accuracy: 0.76580\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss: 0.16904 Training accuracy: 1.00000 Validation accuracy: 0.77360\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss: 0.33453 Training accuracy: 0.92500 Validation accuracy: 0.76520\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss: 0.22835 Training accuracy: 0.95000 Validation accuracy: 0.77020\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.30646 Training accuracy: 0.92500 Validation accuracy: 0.76680\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss: 0.30623 Training accuracy: 0.92500 Validation accuracy: 0.76200\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss: 0.16604 Training accuracy: 1.00000 Validation accuracy: 0.76640\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss: 0.28891 Training accuracy: 0.97500 Validation accuracy: 0.77400\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss: 0.25036 Training accuracy: 0.92500 Validation accuracy: 0.77020\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.35031 Training accuracy: 0.87500 Validation accuracy: 0.76740\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss: 0.26423 Training accuracy: 0.92500 Validation accuracy: 0.77140\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss: 0.18125 Training accuracy: 1.00000 Validation accuracy: 0.76960\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss: 0.28677 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss: 0.21553 Training accuracy: 0.97500 Validation accuracy: 0.77000\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.32967 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss: 0.27189 Training accuracy: 0.95000 Validation accuracy: 0.76060\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss: 0.21444 Training accuracy: 0.95000 Validation accuracy: 0.76320\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss: 0.29092 Training accuracy: 0.92500 Validation accuracy: 0.76820\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss: 0.26413 Training accuracy: 0.92500 Validation accuracy: 0.76740\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.32820 Training accuracy: 0.92500 Validation accuracy: 0.76820\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss: 0.25771 Training accuracy: 0.97500 Validation accuracy: 0.76880\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss: 0.18060 Training accuracy: 0.97500 Validation accuracy: 0.76900\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss: 0.29338 Training accuracy: 0.90000 Validation accuracy: 0.76020\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss: 0.25256 Training accuracy: 0.95000 Validation accuracy: 0.77100\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.36503 Training accuracy: 0.90000 Validation accuracy: 0.76780\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss: 0.27677 Training accuracy: 0.92500 Validation accuracy: 0.76940\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss: 0.16640 Training accuracy: 0.97500 Validation accuracy: 0.77220\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss: 0.30445 Training accuracy: 0.92500 Validation accuracy: 0.76960\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss: 0.27072 Training accuracy: 0.92500 Validation accuracy: 0.76560\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.33833 Training accuracy: 0.95000 Validation accuracy: 0.76400\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss: 0.27068 Training accuracy: 0.97500 Validation accuracy: 0.76820\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss: 0.18497 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss: 0.31421 Training accuracy: 0.95000 Validation accuracy: 0.76760\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss: 0.24570 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.33877 Training accuracy: 0.95000 Validation accuracy: 0.76660\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss: 0.27257 Training accuracy: 0.92500 Validation accuracy: 0.76920\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss: 0.21473 Training accuracy: 0.97500 Validation accuracy: 0.76720\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss: 0.29817 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss: 0.26416 Training accuracy: 0.95000 Validation accuracy: 0.76640\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.35315 Training accuracy: 0.90000 Validation accuracy: 0.77020\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss: 0.25226 Training accuracy: 0.97500 Validation accuracy: 0.76220\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss: 0.19329 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss: 0.32465 Training accuracy: 0.95000 Validation accuracy: 0.77120\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss: 0.18073 Training accuracy: 1.00000 Validation accuracy: 0.77660\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.34254 Training accuracy: 0.90000 Validation accuracy: 0.76320\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss: 0.27306 Training accuracy: 0.90000 Validation accuracy: 0.77080\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss: 0.18292 Training accuracy: 0.97500 Validation accuracy: 0.77040\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss: 0.28889 Training accuracy: 0.95000 Validation accuracy: 0.77680\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss: 0.22611 Training accuracy: 0.97500 Validation accuracy: 0.76940\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.34752 Training accuracy: 0.90000 Validation accuracy: 0.77180\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss: 0.27564 Training accuracy: 0.92500 Validation accuracy: 0.76140\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss: 0.21515 Training accuracy: 0.97500 Validation accuracy: 0.76620\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss: 0.30120 Training accuracy: 0.95000 Validation accuracy: 0.77120\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss: 0.23795 Training accuracy: 0.97500 Validation accuracy: 0.76580\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.31671 Training accuracy: 0.95000 Validation accuracy: 0.76440\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss: 0.28093 Training accuracy: 0.92500 Validation accuracy: 0.76800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215, CIFAR-10 Batch 3:  Loss: 0.18621 Training accuracy: 0.97500 Validation accuracy: 0.76420\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss: 0.28712 Training accuracy: 0.97500 Validation accuracy: 0.77680\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss: 0.24353 Training accuracy: 0.97500 Validation accuracy: 0.77280\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.32402 Training accuracy: 0.95000 Validation accuracy: 0.77360\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss: 0.28189 Training accuracy: 0.90000 Validation accuracy: 0.76740\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss: 0.18474 Training accuracy: 1.00000 Validation accuracy: 0.76980\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss: 0.29290 Training accuracy: 0.97500 Validation accuracy: 0.77480\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss: 0.20373 Training accuracy: 1.00000 Validation accuracy: 0.76980\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.33296 Training accuracy: 0.90000 Validation accuracy: 0.77280\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss: 0.26870 Training accuracy: 0.92500 Validation accuracy: 0.76680\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss: 0.16996 Training accuracy: 0.97500 Validation accuracy: 0.76820\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss: 0.27351 Training accuracy: 0.97500 Validation accuracy: 0.77200\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss: 0.19911 Training accuracy: 1.00000 Validation accuracy: 0.77300\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.32501 Training accuracy: 0.92500 Validation accuracy: 0.76340\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss: 0.28473 Training accuracy: 0.90000 Validation accuracy: 0.76420\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss: 0.17229 Training accuracy: 0.97500 Validation accuracy: 0.75820\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss: 0.27249 Training accuracy: 0.97500 Validation accuracy: 0.77580\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss: 0.21213 Training accuracy: 1.00000 Validation accuracy: 0.77320\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.36369 Training accuracy: 0.92500 Validation accuracy: 0.76640\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss: 0.24655 Training accuracy: 0.97500 Validation accuracy: 0.76960\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss: 0.16297 Training accuracy: 1.00000 Validation accuracy: 0.76740\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss: 0.26577 Training accuracy: 0.97500 Validation accuracy: 0.76820\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss: 0.20019 Training accuracy: 1.00000 Validation accuracy: 0.76880\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.31912 Training accuracy: 0.92500 Validation accuracy: 0.76380\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss: 0.27736 Training accuracy: 0.92500 Validation accuracy: 0.76980\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss: 0.18099 Training accuracy: 0.97500 Validation accuracy: 0.76420\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss: 0.28581 Training accuracy: 0.95000 Validation accuracy: 0.77080\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss: 0.18837 Training accuracy: 1.00000 Validation accuracy: 0.77280\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.33445 Training accuracy: 0.92500 Validation accuracy: 0.77260\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss: 0.27148 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss: 0.16473 Training accuracy: 1.00000 Validation accuracy: 0.77060\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss: 0.26986 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss: 0.21375 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.32914 Training accuracy: 0.92500 Validation accuracy: 0.76680\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss: 0.27196 Training accuracy: 0.95000 Validation accuracy: 0.76260\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss: 0.15919 Training accuracy: 1.00000 Validation accuracy: 0.77320\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss: 0.29063 Training accuracy: 0.95000 Validation accuracy: 0.76740\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss: 0.19372 Training accuracy: 1.00000 Validation accuracy: 0.77260\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.30662 Training accuracy: 0.87500 Validation accuracy: 0.77100\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss: 0.24130 Training accuracy: 0.97500 Validation accuracy: 0.76840\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss: 0.16402 Training accuracy: 1.00000 Validation accuracy: 0.76880\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss: 0.28083 Training accuracy: 0.97500 Validation accuracy: 0.77300\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss: 0.22219 Training accuracy: 0.97500 Validation accuracy: 0.77380\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.28446 Training accuracy: 0.92500 Validation accuracy: 0.77000\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss: 0.24299 Training accuracy: 0.97500 Validation accuracy: 0.77360\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss: 0.18917 Training accuracy: 1.00000 Validation accuracy: 0.77180\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss: 0.28520 Training accuracy: 0.95000 Validation accuracy: 0.77400\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss: 0.19901 Training accuracy: 0.97500 Validation accuracy: 0.77540\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.32434 Training accuracy: 0.92500 Validation accuracy: 0.77020\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss: 0.28062 Training accuracy: 0.92500 Validation accuracy: 0.76480\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss: 0.17774 Training accuracy: 0.97500 Validation accuracy: 0.76520\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss: 0.27448 Training accuracy: 0.90000 Validation accuracy: 0.77280\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss: 0.22206 Training accuracy: 0.97500 Validation accuracy: 0.76940\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.31653 Training accuracy: 0.95000 Validation accuracy: 0.76920\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss: 0.25369 Training accuracy: 0.95000 Validation accuracy: 0.76820\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss: 0.18869 Training accuracy: 1.00000 Validation accuracy: 0.76040\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss: 0.27764 Training accuracy: 0.97500 Validation accuracy: 0.77060\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss: 0.21009 Training accuracy: 0.97500 Validation accuracy: 0.76540\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.34695 Training accuracy: 0.95000 Validation accuracy: 0.76820\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss: 0.23425 Training accuracy: 0.97500 Validation accuracy: 0.76340\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss: 0.17109 Training accuracy: 1.00000 Validation accuracy: 0.76740\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss: 0.27784 Training accuracy: 0.97500 Validation accuracy: 0.76740\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss: 0.19504 Training accuracy: 0.97500 Validation accuracy: 0.77160\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.31715 Training accuracy: 0.90000 Validation accuracy: 0.76980\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss: 0.25699 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss: 0.18633 Training accuracy: 1.00000 Validation accuracy: 0.77000\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss: 0.27230 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss: 0.17731 Training accuracy: 1.00000 Validation accuracy: 0.77140\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.31368 Training accuracy: 0.90000 Validation accuracy: 0.76860\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss: 0.24847 Training accuracy: 0.95000 Validation accuracy: 0.77180\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss: 0.17354 Training accuracy: 0.97500 Validation accuracy: 0.76720\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss: 0.27329 Training accuracy: 0.95000 Validation accuracy: 0.77040\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss: 0.21444 Training accuracy: 1.00000 Validation accuracy: 0.77140\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.31666 Training accuracy: 0.92500 Validation accuracy: 0.76620\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss: 0.29597 Training accuracy: 0.92500 Validation accuracy: 0.76620\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss: 0.17308 Training accuracy: 0.97500 Validation accuracy: 0.76980\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss: 0.26267 Training accuracy: 0.95000 Validation accuracy: 0.77200\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss: 0.21683 Training accuracy: 0.97500 Validation accuracy: 0.77020\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.36513 Training accuracy: 0.87500 Validation accuracy: 0.76980\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss: 0.24883 Training accuracy: 0.97500 Validation accuracy: 0.76540\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss: 0.19098 Training accuracy: 1.00000 Validation accuracy: 0.77340\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss: 0.27621 Training accuracy: 0.92500 Validation accuracy: 0.77320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231, CIFAR-10 Batch 5:  Loss: 0.20842 Training accuracy: 0.97500 Validation accuracy: 0.77280\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.37074 Training accuracy: 0.90000 Validation accuracy: 0.76760\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss: 0.28500 Training accuracy: 0.92500 Validation accuracy: 0.76680\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss: 0.19038 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss: 0.27148 Training accuracy: 0.95000 Validation accuracy: 0.76760\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss: 0.18183 Training accuracy: 0.97500 Validation accuracy: 0.76960\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.33075 Training accuracy: 0.85000 Validation accuracy: 0.76020\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss: 0.27104 Training accuracy: 0.92500 Validation accuracy: 0.76720\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss: 0.19120 Training accuracy: 1.00000 Validation accuracy: 0.76780\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss: 0.28419 Training accuracy: 0.95000 Validation accuracy: 0.75840\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss: 0.22396 Training accuracy: 1.00000 Validation accuracy: 0.76980\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.33538 Training accuracy: 0.90000 Validation accuracy: 0.76700\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss: 0.28100 Training accuracy: 0.92500 Validation accuracy: 0.76920\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss: 0.17599 Training accuracy: 0.97500 Validation accuracy: 0.77200\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss: 0.29143 Training accuracy: 0.95000 Validation accuracy: 0.76680\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss: 0.21931 Training accuracy: 1.00000 Validation accuracy: 0.76980\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.27902 Training accuracy: 0.92500 Validation accuracy: 0.77480\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss: 0.27264 Training accuracy: 0.95000 Validation accuracy: 0.76540\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss: 0.17630 Training accuracy: 1.00000 Validation accuracy: 0.77060\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss: 0.25597 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss: 0.19193 Training accuracy: 1.00000 Validation accuracy: 0.77580\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.33546 Training accuracy: 0.87500 Validation accuracy: 0.76420\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss: 0.30202 Training accuracy: 0.92500 Validation accuracy: 0.76680\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss: 0.17591 Training accuracy: 0.97500 Validation accuracy: 0.77360\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss: 0.30189 Training accuracy: 0.95000 Validation accuracy: 0.77140\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss: 0.20149 Training accuracy: 1.00000 Validation accuracy: 0.77360\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.33744 Training accuracy: 0.87500 Validation accuracy: 0.77360\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss: 0.26428 Training accuracy: 0.95000 Validation accuracy: 0.77840\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss: 0.16706 Training accuracy: 1.00000 Validation accuracy: 0.77840\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss: 0.28557 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss: 0.20613 Training accuracy: 0.97500 Validation accuracy: 0.76660\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.32692 Training accuracy: 0.87500 Validation accuracy: 0.76740\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss: 0.26847 Training accuracy: 0.95000 Validation accuracy: 0.77080\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss: 0.15540 Training accuracy: 1.00000 Validation accuracy: 0.76760\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss: 0.29581 Training accuracy: 0.97500 Validation accuracy: 0.77300\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss: 0.20864 Training accuracy: 1.00000 Validation accuracy: 0.77280\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.34286 Training accuracy: 0.87500 Validation accuracy: 0.77520\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss: 0.26822 Training accuracy: 0.92500 Validation accuracy: 0.76800\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss: 0.19203 Training accuracy: 0.97500 Validation accuracy: 0.76140\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss: 0.27767 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss: 0.20827 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.31019 Training accuracy: 0.92500 Validation accuracy: 0.77420\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss: 0.27539 Training accuracy: 0.97500 Validation accuracy: 0.76420\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss: 0.15214 Training accuracy: 1.00000 Validation accuracy: 0.77160\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss: 0.30940 Training accuracy: 0.95000 Validation accuracy: 0.76460\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss: 0.21557 Training accuracy: 1.00000 Validation accuracy: 0.77280\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.27856 Training accuracy: 0.97500 Validation accuracy: 0.76820\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss: 0.24043 Training accuracy: 1.00000 Validation accuracy: 0.77700\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss: 0.19452 Training accuracy: 0.97500 Validation accuracy: 0.77340\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss: 0.27658 Training accuracy: 0.95000 Validation accuracy: 0.77060\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss: 0.22601 Training accuracy: 1.00000 Validation accuracy: 0.76520\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.32070 Training accuracy: 0.90000 Validation accuracy: 0.76980\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss: 0.23467 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss: 0.16332 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss: 0.29230 Training accuracy: 0.97500 Validation accuracy: 0.76840\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss: 0.19545 Training accuracy: 1.00000 Validation accuracy: 0.77720\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.27362 Training accuracy: 0.95000 Validation accuracy: 0.76380\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss: 0.26986 Training accuracy: 0.92500 Validation accuracy: 0.77340\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss: 0.17891 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss: 0.29866 Training accuracy: 0.97500 Validation accuracy: 0.77780\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss: 0.22532 Training accuracy: 0.95000 Validation accuracy: 0.76740\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.26611 Training accuracy: 0.95000 Validation accuracy: 0.76740\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss: 0.24930 Training accuracy: 0.97500 Validation accuracy: 0.75860\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss: 0.17996 Training accuracy: 0.97500 Validation accuracy: 0.75980\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss: 0.26408 Training accuracy: 0.97500 Validation accuracy: 0.76620\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss: 0.18011 Training accuracy: 1.00000 Validation accuracy: 0.77120\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.28121 Training accuracy: 0.92500 Validation accuracy: 0.76620\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss: 0.27172 Training accuracy: 0.97500 Validation accuracy: 0.76800\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss: 0.19510 Training accuracy: 1.00000 Validation accuracy: 0.76840\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss: 0.28694 Training accuracy: 0.95000 Validation accuracy: 0.76900\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss: 0.21779 Training accuracy: 1.00000 Validation accuracy: 0.77060\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.29019 Training accuracy: 0.90000 Validation accuracy: 0.77200\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss: 0.29936 Training accuracy: 0.95000 Validation accuracy: 0.76280\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss: 0.19108 Training accuracy: 0.97500 Validation accuracy: 0.76320\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss: 0.28336 Training accuracy: 0.97500 Validation accuracy: 0.77060\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss: 0.20936 Training accuracy: 1.00000 Validation accuracy: 0.77400\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.27208 Training accuracy: 0.90000 Validation accuracy: 0.76760\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss: 0.24460 Training accuracy: 0.97500 Validation accuracy: 0.76560\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss: 0.19409 Training accuracy: 0.97500 Validation accuracy: 0.76880\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss: 0.28759 Training accuracy: 0.95000 Validation accuracy: 0.77000\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss: 0.22489 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.30515 Training accuracy: 0.95000 Validation accuracy: 0.77760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248, CIFAR-10 Batch 2:  Loss: 0.26963 Training accuracy: 0.90000 Validation accuracy: 0.76720\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss: 0.17155 Training accuracy: 0.95000 Validation accuracy: 0.77500\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss: 0.27915 Training accuracy: 0.95000 Validation accuracy: 0.76840\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss: 0.19633 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.30197 Training accuracy: 0.92500 Validation accuracy: 0.77060\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss: 0.24217 Training accuracy: 0.95000 Validation accuracy: 0.76860\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss: 0.16264 Training accuracy: 0.97500 Validation accuracy: 0.76380\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss: 0.26154 Training accuracy: 0.97500 Validation accuracy: 0.77300\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss: 0.23683 Training accuracy: 0.95000 Validation accuracy: 0.77120\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.32158 Training accuracy: 0.90000 Validation accuracy: 0.76820\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss: 0.23499 Training accuracy: 0.97500 Validation accuracy: 0.76860\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss: 0.17480 Training accuracy: 1.00000 Validation accuracy: 0.77380\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss: 0.28754 Training accuracy: 0.95000 Validation accuracy: 0.77440\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss: 0.23555 Training accuracy: 0.97500 Validation accuracy: 0.77740\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.32545 Training accuracy: 0.90000 Validation accuracy: 0.76520\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss: 0.21107 Training accuracy: 0.97500 Validation accuracy: 0.76440\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss: 0.18557 Training accuracy: 1.00000 Validation accuracy: 0.77000\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss: 0.25496 Training accuracy: 0.97500 Validation accuracy: 0.77840\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss: 0.19665 Training accuracy: 1.00000 Validation accuracy: 0.77120\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.32477 Training accuracy: 0.90000 Validation accuracy: 0.77600\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss: 0.22323 Training accuracy: 1.00000 Validation accuracy: 0.76940\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss: 0.15471 Training accuracy: 1.00000 Validation accuracy: 0.76980\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss: 0.27173 Training accuracy: 0.97500 Validation accuracy: 0.77520\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss: 0.22045 Training accuracy: 0.97500 Validation accuracy: 0.77080\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.30996 Training accuracy: 0.90000 Validation accuracy: 0.77020\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss: 0.22046 Training accuracy: 1.00000 Validation accuracy: 0.77220\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss: 0.19068 Training accuracy: 1.00000 Validation accuracy: 0.77200\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss: 0.28642 Training accuracy: 0.97500 Validation accuracy: 0.77260\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss: 0.20737 Training accuracy: 1.00000 Validation accuracy: 0.77020\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.27814 Training accuracy: 0.90000 Validation accuracy: 0.77180\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss: 0.24780 Training accuracy: 0.97500 Validation accuracy: 0.77220\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss: 0.18421 Training accuracy: 1.00000 Validation accuracy: 0.76380\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss: 0.26916 Training accuracy: 0.97500 Validation accuracy: 0.76700\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss: 0.16879 Training accuracy: 1.00000 Validation accuracy: 0.76940\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.29677 Training accuracy: 0.90000 Validation accuracy: 0.76900\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss: 0.27672 Training accuracy: 0.92500 Validation accuracy: 0.76380\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss: 0.19431 Training accuracy: 1.00000 Validation accuracy: 0.76880\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss: 0.26203 Training accuracy: 0.97500 Validation accuracy: 0.76740\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss: 0.19841 Training accuracy: 1.00000 Validation accuracy: 0.77240\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.33467 Training accuracy: 0.87500 Validation accuracy: 0.76240\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss: 0.27980 Training accuracy: 0.92500 Validation accuracy: 0.77200\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss: 0.16805 Training accuracy: 1.00000 Validation accuracy: 0.77020\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss: 0.27688 Training accuracy: 0.92500 Validation accuracy: 0.77500\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss: 0.21435 Training accuracy: 1.00000 Validation accuracy: 0.77460\n"
     ]
    }
   ],
   "source": [
    "epochs = 256\n",
    "batch_size = 64\n",
    "keep_probability = 0.4\n",
    "\n",
    "save_model_path = './image_classification_1'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"summary/cifar10/_1\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    c = 0\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer , keep_probability, batch_features, batch_labels)\n",
    "            c+=1\n",
    "            s = sess.run(merged_summary, feed_dict = {x: batch_features, y: batch_labels, keep_prob: keep_probability})\n",
    "            writer.add_summary(s, c)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification_1\n",
      "Testing Accuracy: 0.7575636942675159\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREJPr/q1qghX4twMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb0e678668>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification_1'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy/accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Credit for iPython notebook Tensorboard snippet\n",
    "#https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter/38192374#38192374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/anaconda3/envs/dlnd/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9655452962954241&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;keep_prob&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool/conv_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool/conv_W/TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool/conv_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool/conv_W/mul&quot;\\n  input: &quot;Conv2d_maxpool/conv_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable&quot;\\n  input: &quot;Conv2d_maxpool/conv_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool/conv_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv2d&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;x&quot;\\n  input: &quot;Conv2d_maxpool/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool/conv2d&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;Conv2d_maxpool/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool/conv_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool/conv_weights/tag&quot;\\n  input: &quot;Conv2d_maxpool/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool/conv_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/conv_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool/conv_bias/tag&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/max_pool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;Conv2d_maxpool/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta&quot;\\n  input: &quot;BatchNorm/beta/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_mean/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/moving_mean&quot;\\n  input: &quot;BatchNorm/moving_mean/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_variance/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/moving_variance&quot;\\n  input: &quot;BatchNorm/moving_variance/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/beta/read&quot;\\n  input: &quot;BatchNorm/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;BatchNorm/moments/Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;BatchNorm/moments/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Gather/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Cast&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Gather/indices&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/count&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;BatchNorm/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/SquaredDifference&quot;\\n  op: &quot;SquaredDifference&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;BatchNorm/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/mean_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Sub&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/sufficient_statistics/var_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/SquaredDifference&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/moments/StopGradient&quot;\\n  input: &quot;BatchNorm/moments/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/count&quot;\\n  input: &quot;^BatchNorm/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;^BatchNorm/moments/sufficient_statistics/var_ss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/shifted_mean&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/mean&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/moments/normalize/shifted_mean&quot;\\n  input: &quot;BatchNorm/moments/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;BatchNorm/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/moments/normalize/variance&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm/moments/normalize/Mul&quot;\\n  input: &quot;BatchNorm/moments/normalize/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm/moving_mean/read&quot;\\n  input: &quot;BatchNorm/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg/sub&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm/moving_mean&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg_1/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg_1/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm/moving_variance/read&quot;\\n  input: &quot;BatchNorm/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg_1/sub&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg_1/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm/moving_variance&quot;\\n  input: &quot;BatchNorm/AssignMovingAvg_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;BatchNorm/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm/Reshape&quot;\\n  input: &quot;BatchNorm/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/batchnorm/mul&quot;\\n  input: &quot;BatchNorm/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W/TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W/mul&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv2d&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;BatchNorm/batchnorm/add_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool_1/conv2d&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;Conv2d_maxpool_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/conv_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_weights/tag&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/conv_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/conv_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_bias/tag&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;Conv2d_maxpool_1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta&quot;\\n  input: &quot;BatchNorm_1/beta/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_1/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_mean/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/moving_mean&quot;\\n  input: &quot;BatchNorm_1/moving_mean/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_1/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_variance/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/moving_variance&quot;\\n  input: &quot;BatchNorm_1/moving_variance/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_1/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/beta/read&quot;\\n  input: &quot;BatchNorm_1/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;BatchNorm_1/moments/Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;BatchNorm_1/moments/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Gather/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Cast&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Gather/indices&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/count&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;BatchNorm_1/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/SquaredDifference&quot;\\n  op: &quot;SquaredDifference&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;BatchNorm_1/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Sub&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/SquaredDifference&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/moments/StopGradient&quot;\\n  input: &quot;BatchNorm_1/moments/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/count&quot;\\n  input: &quot;^BatchNorm_1/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;^BatchNorm_1/moments/sufficient_statistics/var_ss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/shifted_mean&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/mean&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/shifted_mean&quot;\\n  input: &quot;BatchNorm_1/moments/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/moments/normalize/variance&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/Mul&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm_1/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm_1/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_1/moving_mean/read&quot;\\n  input: &quot;BatchNorm_1/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg/sub&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm_1/moving_mean&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg_1/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg_1/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_1/moving_variance/read&quot;\\n  input: &quot;BatchNorm_1/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg_1/sub&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg_1/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm_1/moving_variance&quot;\\n  input: &quot;BatchNorm_1/AssignMovingAvg_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm_1/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;BatchNorm_1/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_1/Reshape&quot;\\n  input: &quot;BatchNorm_1/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/batchnorm/mul&quot;\\n  input: &quot;BatchNorm_1/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W/TruncatedNormal&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W/mul&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv2d&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;BatchNorm_1/batchnorm/add_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2d_maxpool_2/conv2d&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;Conv2d_maxpool_2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/conv_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_weights/tag&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/conv_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/conv_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_bias/tag&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;Conv2d_maxpool_2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta&quot;\\n  input: &quot;BatchNorm_2/beta/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_2/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_mean/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/moving_mean&quot;\\n  input: &quot;BatchNorm_2/moving_mean/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_2/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_variance/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/moving_variance&quot;\\n  input: &quot;BatchNorm_2/moving_variance/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_2/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/beta/read&quot;\\n  input: &quot;BatchNorm_2/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;BatchNorm_2/moments/Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;BatchNorm_2/moments/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Gather/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Cast&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Gather/indices&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/count&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;BatchNorm_2/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/SquaredDifference&quot;\\n  op: &quot;SquaredDifference&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;BatchNorm_2/moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Sub&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/SquaredDifference&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/moments/StopGradient&quot;\\n  input: &quot;BatchNorm_2/moments/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/count&quot;\\n  input: &quot;^BatchNorm_2/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;^BatchNorm_2/moments/sufficient_statistics/var_ss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/shifted_mean&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/mean&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/shifted_mean&quot;\\n  input: &quot;BatchNorm_2/moments/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/moments/normalize/variance&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/Mul&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm_2/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm_2/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_2/moving_mean/read&quot;\\n  input: &quot;BatchNorm_2/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg/sub&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm_2/moving_mean&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg_1/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg_1/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_2/moving_variance/read&quot;\\n  input: &quot;BatchNorm_2/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg_1/sub&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg_1/decay&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/AssignMovingAvg_1&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;BatchNorm_2/moving_variance&quot;\\n  input: &quot;BatchNorm_2/AssignMovingAvg_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/variance&quot;\\n  input: &quot;BatchNorm_2/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;BatchNorm_2/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/mean&quot;\\n  input: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;BatchNorm_2/Reshape&quot;\\n  input: &quot;BatchNorm_2/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/batchnorm/mul&quot;\\n  input: &quot;BatchNorm_2/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Flatten/flatten/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\000\\\\004\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Flatten/flatten&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/batchnorm/add_1&quot;\\n  input: &quot;Flatten/flatten/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Flatten/flatten&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;dropout/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;dropout/random_uniform/max&quot;\\n  input: &quot;dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout/random_uniform/RandomUniform&quot;\\n  input: &quot;dropout/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dropout/random_uniform/mul&quot;\\n  input: &quot;dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;keep_prob&quot;\\n  input: &quot;dropout/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;dropout/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;Flatten/flatten&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout/div&quot;\\n  input: &quot;dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\004\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;FC/FC_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;FC/FC_W/TruncatedNormal&quot;\\n  input: &quot;FC/FC_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;FC/FC_W/mul&quot;\\n  input: &quot;FC/FC_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1024\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable&quot;\\n  input: &quot;FC/FC_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1&quot;\\n  input: &quot;FC/FC_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dropout/mul&quot;\\n  input: &quot;FC/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;FC/MatMul&quot;\\n  input: &quot;FC/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;FC/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;FC/FC_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;FC/FC_weights/tag&quot;\\n  input: &quot;FC/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;FC/FC_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/FC_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;FC/FC_bias/tag&quot;\\n  input: &quot;FC/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;FC/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;dropout_1/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;dropout_1/random_uniform/max&quot;\\n  input: &quot;dropout_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout_1/random_uniform/RandomUniform&quot;\\n  input: &quot;dropout_1/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dropout_1/random_uniform/mul&quot;\\n  input: &quot;dropout_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;keep_prob&quot;\\n  input: &quot;dropout_1/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;dropout_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;FC/Relu&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout_1/div&quot;\\n  input: &quot;dropout_1/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;FC_1/FC_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;FC_1/FC_W/TruncatedNormal&quot;\\n  input: &quot;FC_1/FC_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;FC_1/FC_W/mul&quot;\\n  input: &quot;FC_1/FC_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable&quot;\\n  input: &quot;FC_1/FC_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1&quot;\\n  input: &quot;FC_1/FC_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dropout_1/mul&quot;\\n  input: &quot;FC_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;FC_1/MatMul&quot;\\n  input: &quot;FC_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;FC_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;FC_1/FC_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;FC_1/FC_weights/tag&quot;\\n  input: &quot;FC_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;FC_1/FC_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/FC_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;FC_1/FC_bias/tag&quot;\\n  input: &quot;FC_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\001\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Output/Out_W/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Output/Out_W/TruncatedNormal&quot;\\n  input: &quot;Output/Out_W/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_W&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Output/Out_W/mul&quot;\\n  input: &quot;Output/Out_W/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable&quot;\\n  input: &quot;Output/Out_W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Out_b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1&quot;\\n  input: &quot;Output/Out_b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;FC_1/Relu&quot;\\n  input: &quot;Output/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Output/MatMul&quot;\\n  input: &quot;Output/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Output_weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Output/Output_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Output_weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Output/Output_weights/tag&quot;\\n  input: &quot;Output/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Output_bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Output/Output_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Output_bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;Output/Output_bias/tag&quot;\\n  input: &quot;Output/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Xent/Rank_1&quot;\\n  input: &quot;Xent/Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Xent/Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Xent/Shape_1&quot;\\n  input: &quot;Xent/Slice/begin&quot;\\n  input: &quot;Xent/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Xent/concat/values_0&quot;\\n  input: &quot;Xent/Slice&quot;\\n  input: &quot;Xent/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logits&quot;\\n  input: &quot;Xent/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Xent/Rank_2&quot;\\n  input: &quot;Xent/Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Xent/Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Xent/Shape_2&quot;\\n  input: &quot;Xent/Slice_1/begin&quot;\\n  input: &quot;Xent/Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat_1/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Xent/concat_1/values_0&quot;\\n  input: &quot;Xent/Slice_1&quot;\\n  input: &quot;Xent/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;y&quot;\\n  input: &quot;Xent/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/SoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Xent/Reshape&quot;\\n  input: &quot;Xent/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Xent/Rank&quot;\\n  input: &quot;Xent/Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;Xent/Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;Xent/Shape&quot;\\n  input: &quot;Xent/Slice_2/begin&quot;\\n  input: &quot;Xent/Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Xent/SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;Xent/Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Xent/Reshape_2&quot;\\n  input: &quot;Xent/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/softmax_cross_entropy_with_logits/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;Xent/softmax_cross_entropy_with_logits&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xent/softmax_cross_entropy_with_logits&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;Xent/softmax_cross_entropy_with_logits/tags&quot;\\n  input: &quot;Xent/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Xent/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Reshape&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Xent/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Shape_1&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Shape_2&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Prod_1&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Prod&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Tile&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Xent/SoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Xent/Mean_grad/truediv&quot;\\n  input: &quot;train/gradients/Xent/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;Xent/SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/Xent/Reshape_2_grad/Reshape&quot;\\n  input: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;Xent/SoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Xent/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Xent/SoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/Xent/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Output/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/Output/add_grad/Shape&quot;\\n  input: &quot;train/gradients/Output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Xent/Reshape_grad/Reshape&quot;\\n  input: &quot;train/gradients/Output/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Output/add_grad/Sum&quot;\\n  input: &quot;train/gradients/Output/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Xent/Reshape_grad/Reshape&quot;\\n  input: &quot;train/gradients/Output/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Output/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/Output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Output/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Output/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Output/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Output/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Output/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/Output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/Output/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Output/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;FC_1/Relu&quot;\\n  input: &quot;train/gradients/Output/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Output/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/Output/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Output/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Output/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/Output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Output/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Output/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Output/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/Output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Output/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/Output/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;FC_1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;FC_1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 256\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Shape&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/FC_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Sum&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/FC_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/FC_1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/FC_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/FC_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/FC_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;FC_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dropout_1/mul&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/FC_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/FC_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/FC_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/FC_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dropout_1/div&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dropout_1/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/FC_1/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dropout_1/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/mul&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout_1/div&quot;\\n  input: &quot;train/gradients/FC_1/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dropout_1/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout_1/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout_1/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dropout_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout_1/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;FC/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Shape&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/RealDiv&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Sum&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;FC/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Neg&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/RealDiv_1&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/dropout_1/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/mul&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dropout_1/div_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout_1/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout_1/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout_1/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout_1/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dropout_1/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout_1/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dropout_1/div_grad/tuple/control_dependency&quot;\\n  input: &quot;FC/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;FC/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/FC/add_grad/Shape&quot;\\n  input: &quot;train/gradients/FC/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/FC/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/FC/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/FC/add_grad/Sum&quot;\\n  input: &quot;train/gradients/FC/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/FC/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/FC/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/FC/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/FC/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/FC/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/FC/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/FC/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/FC/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/FC/add_grad/tuple/control_dependency&quot;\\n  input: &quot;FC/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dropout/mul&quot;\\n  input: &quot;train/gradients/FC/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/FC/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/FC/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/FC/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/FC/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/FC/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/FC/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/FC/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/FC/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dropout/div&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/FC/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/mul&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout/div&quot;\\n  input: &quot;train/gradients/FC/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dropout/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Flatten/flatten&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Shape&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout/div_grad/RealDiv&quot;\\n  input: &quot;train/gradients/dropout/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Sum&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;Flatten/flatten&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Neg&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/dropout/div_grad/RealDiv_1&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/dropout/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/dropout/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dropout/div_grad/mul&quot;\\n  input: &quot;train/gradients/dropout/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dropout/div_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dropout/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dropout/div_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dropout/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dropout/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Flatten/flatten_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_2/batchnorm/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Flatten/flatten_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dropout/div_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/Flatten/flatten_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_2/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Flatten/flatten_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Flatten/flatten_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 64\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/mean&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  op: &quot;RsqrtGrad&quot;\\n  input: &quot;BatchNorm_2/batchnorm/Rsqrt&quot;\\n  input: &quot;train/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/variance_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul/x&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/SquaredDifference&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Square_grad/mul_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/AddN_1&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;train/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;BatchNorm_2/moments/StopGradient&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  op: &quot;ReciprocalGrad&quot;\\n  input: &quot;BatchNorm_2/moments/normalize/divisor&quot;\\n  input: &quot;train/gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Rank&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/range_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/transpose&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/Reshape_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/moments/Reshape_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moments/sufficient_statistics/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_2/moments/sufficient_statistics/Gather/indices&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_2/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_2/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_2/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/max_pool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool_2/Relu&quot;\\n  input: &quot;Conv2d_maxpool_2/max_pool&quot;\\n  input: &quot;train/gradients/AddN_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/max_pool_grad/MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool_2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/conv2d&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 64\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_1/batchnorm/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Shape&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/read&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;BatchNorm_1/batchnorm/add_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Shape_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_2/conv2d_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_1/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/mean&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  op: &quot;RsqrtGrad&quot;\\n  input: &quot;BatchNorm_1/batchnorm/Rsqrt&quot;\\n  input: &quot;train/gradients/AddN_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/variance_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul/x&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/SquaredDifference&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Square_grad/mul_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/AddN_6&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;train/gradients/AddN_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;BatchNorm_1/moments/StopGradient&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  op: &quot;ReciprocalGrad&quot;\\n  input: &quot;BatchNorm_1/moments/normalize/divisor&quot;\\n  input: &quot;train/gradients/AddN_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Rank&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/range_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Prod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/transpose&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/Reshape_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/moments/Reshape_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moments/sufficient_statistics/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm_1/moments/sufficient_statistics/Gather/indices&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_9&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm_1/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm_1/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm_1/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/max_pool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool_1/Relu&quot;\\n  input: &quot;Conv2d_maxpool_1/max_pool&quot;\\n  input: &quot;train/gradients/AddN_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/max_pool_grad/MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool_1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/conv2d&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm/batchnorm/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Shape&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/read&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;BatchNorm/batchnorm/add_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Shape_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool_1/conv2d_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/normalize/mean&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_10&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  op: &quot;RsqrtGrad&quot;\\n  input: &quot;BatchNorm/batchnorm/Rsqrt&quot;\\n  input: &quot;train/gradients/AddN_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/batchnorm/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/batchnorm/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/variance_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  input: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/var_ss&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul/x&quot;\\n  input: &quot;BatchNorm/moments/normalize/shifted_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/variance_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/SquaredDifference&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/var_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_11&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Square_grad/mul_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/AddN_11&quot;\\n  input: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/mean_ss&quot;\\n  input: &quot;train/gradients/AddN_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/scalar&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;BatchNorm/moments/StopGradient&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/var_ss_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Sum_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/mean_ss/reduction_indices&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_12&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/shifted_mean_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/normalize/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  op: &quot;ReciprocalGrad&quot;\\n  input: &quot;BatchNorm/moments/normalize/divisor&quot;\\n  input: &quot;train/gradients/AddN_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/mean_ss_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Neg&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Const&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/add&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range/start&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/normalize/divisor_grad/ReciprocalGrad&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1/start&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Rank&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1/delta&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  op: &quot;ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/range_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/concat/axis&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Gather&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  op: &quot;Gather&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/ListDiff&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Gather_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Const_1&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Gather&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Prod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Prod_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/transpose&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  op: &quot;Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_2&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod_1/axis&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;exclusive&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;reverse&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Cumprod_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  op: &quot;InvertPermutation&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_3&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/InvertPermutation&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Tile&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/transpose_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/mul_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_13&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/Reshape_grad/Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/moments/Reshape_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moments/sufficient_statistics/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Size&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Shape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack_1&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/strided_slice&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/count_grad/Reshape_4&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;BatchNorm/moments/sufficient_statistics/Gather/indices&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Gather_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN_14&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/BatchNorm/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/SquaredDifference_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/BatchNorm/moments/sufficient_statistics/Sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/BatchNorm/batchnorm/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/max_pool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool/Relu&quot;\\n  input: &quot;Conv2d_maxpool/max_pool&quot;\\n  input: &quot;train/gradients/AddN_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/max_pool_grad/MaxPoolGrad&quot;\\n  input: &quot;Conv2d_maxpool/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2d_maxpool/conv2d&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 16\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Shape&quot;\\n  input: &quot;Conv2d_maxpool/Variable/read&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;x&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Shape_1&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^train/gradients/Conv2d_maxpool/conv2d_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/Conv2d_maxpool/conv2d_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta1_power&quot;\\n  input: &quot;train/beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta2_power&quot;\\n  input: &quot;train/beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta/Adam&quot;\\n  input: &quot;BatchNorm/beta/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta/Adam_1&quot;\\n  input: &quot;BatchNorm/beta/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 16\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 16\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 16\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_1/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta/Adam&quot;\\n  input: &quot;BatchNorm_1/beta/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_1/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_1/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2d_maxpool_2/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta/Adam&quot;\\n  input: &quot;BatchNorm_2/beta/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_2/beta/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;BatchNorm_2/beta/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1024\\n          }\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1024\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable/Adam&quot;\\n  input: &quot;FC/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1024\\n          }\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1024\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable/Adam_1&quot;\\n  input: &quot;FC/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1/Adam&quot;\\n  input: &quot;FC/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1/Adam_1&quot;\\n  input: &quot;FC/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable/Adam&quot;\\n  input: &quot;FC_1/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable/Adam_1&quot;\\n  input: &quot;FC_1/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1/Adam&quot;\\n  input: &quot;FC_1/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;FC_1/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable/Adam&quot;\\n  input: &quot;Output/Variable/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable/Adam_1&quot;\\n  input: &quot;Output/Variable/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1/Adam&quot;\\n  input: &quot;Output/Variable_1/Adam/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam_1/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1/Adam_1&quot;\\n  input: &quot;Output/Variable_1/Adam_1/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Output/Variable_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Output/Variable_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool/Variable&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/conv2d_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_BatchNorm/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;BatchNorm/beta&quot;\\n  input: &quot;BatchNorm/beta/Adam&quot;\\n  input: &quot;BatchNorm/beta/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/BatchNorm/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool_1/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/conv2d_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool_1/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_BatchNorm_1/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;BatchNorm_1/beta&quot;\\n  input: &quot;BatchNorm_1/beta/Adam&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/BatchNorm_1/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool_2/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/conv2d_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Conv2d_maxpool_2/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Conv2d_maxpool_2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_BatchNorm_2/beta/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;BatchNorm_2/beta&quot;\\n  input: &quot;BatchNorm_2/beta/Adam&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/BatchNorm_2/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_FC/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;FC/Variable&quot;\\n  input: &quot;FC/Variable/Adam&quot;\\n  input: &quot;FC/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/FC/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_FC/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;FC/Variable_1&quot;\\n  input: &quot;FC/Variable_1/Adam&quot;\\n  input: &quot;FC/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/FC/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_FC_1/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;FC_1/Variable&quot;\\n  input: &quot;FC_1/Variable/Adam&quot;\\n  input: &quot;FC_1/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/FC_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_FC_1/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;FC_1/Variable_1&quot;\\n  input: &quot;FC_1/Variable_1/Adam&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/FC_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Output/Variable/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Output/Variable&quot;\\n  input: &quot;Output/Variable/Adam&quot;\\n  input: &quot;Output/Variable/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Output/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/update_Output/Variable_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Output/Variable_1&quot;\\n  input: &quot;Output/Variable_1/Adam&quot;\\n  input: &quot;Output/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/learning_rate&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;train/Adam/epsilon&quot;\\n  input: &quot;train/gradients/Output/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/beta1_power/read&quot;\\n  input: &quot;train/Adam/beta1&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_1/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_2/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable_1/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta1_power&quot;\\n  input: &quot;train/Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/beta2_power/read&quot;\\n  input: &quot;train/Adam/beta2&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_1/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_2/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable_1/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta2_power&quot;\\n  input: &quot;train/Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_1/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Conv2d_maxpool_2/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_BatchNorm_2/beta/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_FC_1/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable/ApplyAdam&quot;\\n  input: &quot;^train/Adam/update_Output/Variable_1/ApplyAdam&quot;\\n  input: &quot;^train/Adam/Assign&quot;\\n  input: &quot;^train/Adam/Assign_1&quot;\\n}\\nnode {\\n  name: &quot;accuracy/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;logits&quot;\\n  input: &quot;accuracy/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/ArgMax_1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/ArgMax_1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;y&quot;\\n  input: &quot;accuracy/ArgMax_1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;accuracy/ArgMax&quot;\\n  input: &quot;accuracy/ArgMax_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;accuracy/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;accuracy/Cast&quot;\\n  input: &quot;accuracy/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/accuracy_1/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;accuracy/accuracy_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy/accuracy_1&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;accuracy/accuracy_1/tags&quot;\\n  input: &quot;accuracy/accuracy&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Conv2d_maxpool/Variable/Assign&quot;\\n  input: &quot;^Conv2d_maxpool/Variable_1/Assign&quot;\\n  input: &quot;^BatchNorm/beta/Assign&quot;\\n  input: &quot;^BatchNorm/moving_mean/Assign&quot;\\n  input: &quot;^BatchNorm/moving_variance/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable_1/Assign&quot;\\n  input: &quot;^BatchNorm_1/beta/Assign&quot;\\n  input: &quot;^BatchNorm_1/moving_mean/Assign&quot;\\n  input: &quot;^BatchNorm_1/moving_variance/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable_1/Assign&quot;\\n  input: &quot;^BatchNorm_2/beta/Assign&quot;\\n  input: &quot;^BatchNorm_2/moving_mean/Assign&quot;\\n  input: &quot;^BatchNorm_2/moving_variance/Assign&quot;\\n  input: &quot;^FC/Variable/Assign&quot;\\n  input: &quot;^FC/Variable_1/Assign&quot;\\n  input: &quot;^FC_1/Variable/Assign&quot;\\n  input: &quot;^FC_1/Variable_1/Assign&quot;\\n  input: &quot;^Output/Variable/Assign&quot;\\n  input: &quot;^Output/Variable_1/Assign&quot;\\n  input: &quot;^train/beta1_power/Assign&quot;\\n  input: &quot;^train/beta2_power/Assign&quot;\\n  input: &quot;^Conv2d_maxpool/Variable/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool/Variable/Adam_1/Assign&quot;\\n  input: &quot;^Conv2d_maxpool/Variable_1/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool/Variable_1/Adam_1/Assign&quot;\\n  input: &quot;^BatchNorm/beta/Adam/Assign&quot;\\n  input: &quot;^BatchNorm/beta/Adam_1/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable/Adam_1/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable_1/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_1/Variable_1/Adam_1/Assign&quot;\\n  input: &quot;^BatchNorm_1/beta/Adam/Assign&quot;\\n  input: &quot;^BatchNorm_1/beta/Adam_1/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable/Adam_1/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable_1/Adam/Assign&quot;\\n  input: &quot;^Conv2d_maxpool_2/Variable_1/Adam_1/Assign&quot;\\n  input: &quot;^BatchNorm_2/beta/Adam/Assign&quot;\\n  input: &quot;^BatchNorm_2/beta/Adam_1/Assign&quot;\\n  input: &quot;^FC/Variable/Adam/Assign&quot;\\n  input: &quot;^FC/Variable/Adam_1/Assign&quot;\\n  input: &quot;^FC/Variable_1/Adam/Assign&quot;\\n  input: &quot;^FC/Variable_1/Adam_1/Assign&quot;\\n  input: &quot;^FC_1/Variable/Adam/Assign&quot;\\n  input: &quot;^FC_1/Variable/Adam_1/Assign&quot;\\n  input: &quot;^FC_1/Variable_1/Adam/Assign&quot;\\n  input: &quot;^FC_1/Variable_1/Adam_1/Assign&quot;\\n  input: &quot;^Output/Variable/Adam/Assign&quot;\\n  input: &quot;^Output/Variable/Adam_1/Assign&quot;\\n  input: &quot;^Output/Variable_1/Adam/Assign&quot;\\n  input: &quot;^Output/Variable_1/Adam_1/Assign&quot;\\n}\\nnode {\\n  name: &quot;Merge/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;Conv2d_maxpool/conv_weights&quot;\\n  input: &quot;Conv2d_maxpool/conv_bias&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_weights&quot;\\n  input: &quot;Conv2d_maxpool_1/conv_bias&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_weights&quot;\\n  input: &quot;Conv2d_maxpool_2/conv_bias&quot;\\n  input: &quot;FC/FC_weights&quot;\\n  input: &quot;FC/FC_bias&quot;\\n  input: &quot;FC_1/FC_weights&quot;\\n  input: &quot;FC_1/FC_bias&quot;\\n  input: &quot;Output/Output_weights&quot;\\n  input: &quot;Output/Output_bias&quot;\\n  input: &quot;Xent/softmax_cross_entropy_with_logits&quot;\\n  input: &quot;accuracy/accuracy_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 14\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 53\\n          }\\n        }\\n        string_val: &quot;BatchNorm/beta&quot;\\n        string_val: &quot;BatchNorm/beta/Adam&quot;\\n        string_val: &quot;BatchNorm/beta/Adam_1&quot;\\n        string_val: &quot;BatchNorm/moving_mean&quot;\\n        string_val: &quot;BatchNorm/moving_variance&quot;\\n        string_val: &quot;BatchNorm_1/beta&quot;\\n        string_val: &quot;BatchNorm_1/beta/Adam&quot;\\n        string_val: &quot;BatchNorm_1/beta/Adam_1&quot;\\n        string_val: &quot;BatchNorm_1/moving_mean&quot;\\n        string_val: &quot;BatchNorm_1/moving_variance&quot;\\n        string_val: &quot;BatchNorm_2/beta&quot;\\n        string_val: &quot;BatchNorm_2/beta/Adam&quot;\\n        string_val: &quot;BatchNorm_2/beta/Adam_1&quot;\\n        string_val: &quot;BatchNorm_2/moving_mean&quot;\\n        string_val: &quot;BatchNorm_2/moving_variance&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable_1&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n        string_val: &quot;FC/Variable&quot;\\n        string_val: &quot;FC/Variable/Adam&quot;\\n        string_val: &quot;FC/Variable/Adam_1&quot;\\n        string_val: &quot;FC/Variable_1&quot;\\n        string_val: &quot;FC/Variable_1/Adam&quot;\\n        string_val: &quot;FC/Variable_1/Adam_1&quot;\\n        string_val: &quot;FC_1/Variable&quot;\\n        string_val: &quot;FC_1/Variable/Adam&quot;\\n        string_val: &quot;FC_1/Variable/Adam_1&quot;\\n        string_val: &quot;FC_1/Variable_1&quot;\\n        string_val: &quot;FC_1/Variable_1/Adam&quot;\\n        string_val: &quot;FC_1/Variable_1/Adam_1&quot;\\n        string_val: &quot;Output/Variable&quot;\\n        string_val: &quot;Output/Variable/Adam&quot;\\n        string_val: &quot;Output/Variable/Adam_1&quot;\\n        string_val: &quot;Output/Variable_1&quot;\\n        string_val: &quot;Output/Variable_1/Adam&quot;\\n        string_val: &quot;Output/Variable_1/Adam_1&quot;\\n        string_val: &quot;train/beta1_power&quot;\\n        string_val: &quot;train/beta2_power&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 53\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;BatchNorm/beta&quot;\\n  input: &quot;BatchNorm/beta/Adam&quot;\\n  input: &quot;BatchNorm/beta/Adam_1&quot;\\n  input: &quot;BatchNorm/moving_mean&quot;\\n  input: &quot;BatchNorm/moving_variance&quot;\\n  input: &quot;BatchNorm_1/beta&quot;\\n  input: &quot;BatchNorm_1/beta/Adam&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  input: &quot;BatchNorm_1/moving_mean&quot;\\n  input: &quot;BatchNorm_1/moving_variance&quot;\\n  input: &quot;BatchNorm_2/beta&quot;\\n  input: &quot;BatchNorm_2/beta/Adam&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  input: &quot;BatchNorm_2/moving_mean&quot;\\n  input: &quot;BatchNorm_2/moving_variance&quot;\\n  input: &quot;Conv2d_maxpool/Variable&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  input: &quot;FC/Variable&quot;\\n  input: &quot;FC/Variable/Adam&quot;\\n  input: &quot;FC/Variable/Adam_1&quot;\\n  input: &quot;FC/Variable_1&quot;\\n  input: &quot;FC/Variable_1/Adam&quot;\\n  input: &quot;FC/Variable_1/Adam_1&quot;\\n  input: &quot;FC_1/Variable&quot;\\n  input: &quot;FC_1/Variable/Adam&quot;\\n  input: &quot;FC_1/Variable/Adam_1&quot;\\n  input: &quot;FC_1/Variable_1&quot;\\n  input: &quot;FC_1/Variable_1/Adam&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1&quot;\\n  input: &quot;Output/Variable&quot;\\n  input: &quot;Output/Variable/Adam&quot;\\n  input: &quot;Output/Variable/Adam_1&quot;\\n  input: &quot;Output/Variable_1&quot;\\n  input: &quot;Output/Variable_1/Adam&quot;\\n  input: &quot;Output/Variable_1/Adam_1&quot;\\n  input: &quot;train/beta1_power&quot;\\n  input: &quot;train/beta2_power&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm/beta/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta/Adam&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm/beta/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/beta/Adam_1&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/moving_mean&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm/moving_variance&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_1/beta/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_6/tensor_names&quot;\\n  input: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta/Adam&quot;\\n  input: &quot;save/RestoreV2_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_1/beta/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_7/tensor_names&quot;\\n  input: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/beta/Adam_1&quot;\\n  input: &quot;save/RestoreV2_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_8/tensor_names&quot;\\n  input: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/moving_mean&quot;\\n  input: &quot;save/RestoreV2_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_9/tensor_names&quot;\\n  input: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_1/moving_variance&quot;\\n  input: &quot;save/RestoreV2_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_10/tensor_names&quot;\\n  input: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta&quot;\\n  input: &quot;save/RestoreV2_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_2/beta/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_11/tensor_names&quot;\\n  input: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta/Adam&quot;\\n  input: &quot;save/RestoreV2_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_12/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_2/beta/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_12/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_12&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_12/tensor_names&quot;\\n  input: &quot;save/RestoreV2_12/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_12&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/beta/Adam_1&quot;\\n  input: &quot;save/RestoreV2_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_13/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_13/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_13&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_13/tensor_names&quot;\\n  input: &quot;save/RestoreV2_13/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_13&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/moving_mean&quot;\\n  input: &quot;save/RestoreV2_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_14/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_14/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_14&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_14/tensor_names&quot;\\n  input: &quot;save/RestoreV2_14/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_14&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;BatchNorm_2/moving_variance&quot;\\n  input: &quot;save/RestoreV2_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@BatchNorm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_15/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_15/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_15&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_15/tensor_names&quot;\\n  input: &quot;save/RestoreV2_15/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_15&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable&quot;\\n  input: &quot;save/RestoreV2_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_16/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_16/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_16&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_16/tensor_names&quot;\\n  input: &quot;save/RestoreV2_16/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_16&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_17/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_17/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_17&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_17/tensor_names&quot;\\n  input: &quot;save/RestoreV2_17/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_17&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_18/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_18/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_18&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_18/tensor_names&quot;\\n  input: &quot;save/RestoreV2_18/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_18&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1&quot;\\n  input: &quot;save/RestoreV2_18&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_19/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_19/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_19&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_19/tensor_names&quot;\\n  input: &quot;save/RestoreV2_19/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_19&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_20/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_20/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_20&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_20/tensor_names&quot;\\n  input: &quot;save/RestoreV2_20/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_20&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_20&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_21/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_21/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_21&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_21/tensor_names&quot;\\n  input: &quot;save/RestoreV2_21/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_21&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable&quot;\\n  input: &quot;save/RestoreV2_21&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_22/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_22/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_22&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_22/tensor_names&quot;\\n  input: &quot;save/RestoreV2_22/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_22&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_23/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_23/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_23&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_23/tensor_names&quot;\\n  input: &quot;save/RestoreV2_23/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_23&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_23&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_24/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_24/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_24&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_24/tensor_names&quot;\\n  input: &quot;save/RestoreV2_24/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_24&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1&quot;\\n  input: &quot;save/RestoreV2_24&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_25/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_25/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_25&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_25/tensor_names&quot;\\n  input: &quot;save/RestoreV2_25/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_25&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_25&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_26/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_26/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_26&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_26/tensor_names&quot;\\n  input: &quot;save/RestoreV2_26/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_26&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_1/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_26&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_27/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_27/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_27&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_27/tensor_names&quot;\\n  input: &quot;save/RestoreV2_27/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_27&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable&quot;\\n  input: &quot;save/RestoreV2_27&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_28/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_28/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_28&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_28/tensor_names&quot;\\n  input: &quot;save/RestoreV2_28/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_28&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_28&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_29/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_29/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_29&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_29/tensor_names&quot;\\n  input: &quot;save/RestoreV2_29/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_29&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_29&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_30/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_30/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_30&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_30/tensor_names&quot;\\n  input: &quot;save/RestoreV2_30/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_30&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1&quot;\\n  input: &quot;save/RestoreV2_30&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_31/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_31/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_31&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_31/tensor_names&quot;\\n  input: &quot;save/RestoreV2_31/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_31&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_31&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_32/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_32/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_32&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_32/tensor_names&quot;\\n  input: &quot;save/RestoreV2_32/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_32&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Conv2d_maxpool_2/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_32&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_33/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_33/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_33&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_33/tensor_names&quot;\\n  input: &quot;save/RestoreV2_33/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_33&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable&quot;\\n  input: &quot;save/RestoreV2_33&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_34/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_34/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_34&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_34/tensor_names&quot;\\n  input: &quot;save/RestoreV2_34/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_34&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_34&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_35/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_35/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_35&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_35/tensor_names&quot;\\n  input: &quot;save/RestoreV2_35/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_35&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_35&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_36/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_36/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_36&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_36/tensor_names&quot;\\n  input: &quot;save/RestoreV2_36/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_36&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1&quot;\\n  input: &quot;save/RestoreV2_36&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_37/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_37/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_37&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_37/tensor_names&quot;\\n  input: &quot;save/RestoreV2_37/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_37&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_37&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_38/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_38/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_38&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_38/tensor_names&quot;\\n  input: &quot;save/RestoreV2_38/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_38&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_38&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_39/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_39/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_39&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_39/tensor_names&quot;\\n  input: &quot;save/RestoreV2_39/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_39&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable&quot;\\n  input: &quot;save/RestoreV2_39&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_40/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_40/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_40&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_40/tensor_names&quot;\\n  input: &quot;save/RestoreV2_40/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_40&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_40&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_41/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_41/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_41&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_41/tensor_names&quot;\\n  input: &quot;save/RestoreV2_41/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_41&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_41&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_42/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_42/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_42&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_42/tensor_names&quot;\\n  input: &quot;save/RestoreV2_42/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_42&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1&quot;\\n  input: &quot;save/RestoreV2_42&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_43/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_43/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_43&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_43/tensor_names&quot;\\n  input: &quot;save/RestoreV2_43/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_43&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_43&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_44/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;FC_1/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_44/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_44&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_44/tensor_names&quot;\\n  input: &quot;save/RestoreV2_44/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_44&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;FC_1/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_44&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@FC_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_45/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_45/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_45&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_45/tensor_names&quot;\\n  input: &quot;save/RestoreV2_45/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_45&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable&quot;\\n  input: &quot;save/RestoreV2_45&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_46/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_46/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_46&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_46/tensor_names&quot;\\n  input: &quot;save/RestoreV2_46/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_46&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable/Adam&quot;\\n  input: &quot;save/RestoreV2_46&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_47/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_47/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_47&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_47/tensor_names&quot;\\n  input: &quot;save/RestoreV2_47/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_47&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable/Adam_1&quot;\\n  input: &quot;save/RestoreV2_47&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_48/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_48/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_48&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_48/tensor_names&quot;\\n  input: &quot;save/RestoreV2_48/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_48&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1&quot;\\n  input: &quot;save/RestoreV2_48&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_49/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable_1/Adam&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_49/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_49&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_49/tensor_names&quot;\\n  input: &quot;save/RestoreV2_49/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_49&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1/Adam&quot;\\n  input: &quot;save/RestoreV2_49&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_50/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;Output/Variable_1/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_50/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_50&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_50/tensor_names&quot;\\n  input: &quot;save/RestoreV2_50/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_50&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Output/Variable_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2_50&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Output/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_51/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;train/beta1_power&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_51/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_51&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_51/tensor_names&quot;\\n  input: &quot;save/RestoreV2_51/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_51&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta1_power&quot;\\n  input: &quot;save/RestoreV2_51&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_52/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;train/beta2_power&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_52/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_52&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_52/tensor_names&quot;\\n  input: &quot;save/RestoreV2_52/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_52&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;train/beta2_power&quot;\\n  input: &quot;save/RestoreV2_52&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Conv2d_maxpool/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n  input: &quot;^save/Assign_12&quot;\\n  input: &quot;^save/Assign_13&quot;\\n  input: &quot;^save/Assign_14&quot;\\n  input: &quot;^save/Assign_15&quot;\\n  input: &quot;^save/Assign_16&quot;\\n  input: &quot;^save/Assign_17&quot;\\n  input: &quot;^save/Assign_18&quot;\\n  input: &quot;^save/Assign_19&quot;\\n  input: &quot;^save/Assign_20&quot;\\n  input: &quot;^save/Assign_21&quot;\\n  input: &quot;^save/Assign_22&quot;\\n  input: &quot;^save/Assign_23&quot;\\n  input: &quot;^save/Assign_24&quot;\\n  input: &quot;^save/Assign_25&quot;\\n  input: &quot;^save/Assign_26&quot;\\n  input: &quot;^save/Assign_27&quot;\\n  input: &quot;^save/Assign_28&quot;\\n  input: &quot;^save/Assign_29&quot;\\n  input: &quot;^save/Assign_30&quot;\\n  input: &quot;^save/Assign_31&quot;\\n  input: &quot;^save/Assign_32&quot;\\n  input: &quot;^save/Assign_33&quot;\\n  input: &quot;^save/Assign_34&quot;\\n  input: &quot;^save/Assign_35&quot;\\n  input: &quot;^save/Assign_36&quot;\\n  input: &quot;^save/Assign_37&quot;\\n  input: &quot;^save/Assign_38&quot;\\n  input: &quot;^save/Assign_39&quot;\\n  input: &quot;^save/Assign_40&quot;\\n  input: &quot;^save/Assign_41&quot;\\n  input: &quot;^save/Assign_42&quot;\\n  input: &quot;^save/Assign_43&quot;\\n  input: &quot;^save/Assign_44&quot;\\n  input: &quot;^save/Assign_45&quot;\\n  input: &quot;^save/Assign_46&quot;\\n  input: &quot;^save/Assign_47&quot;\\n  input: &quot;^save/Assign_48&quot;\\n  input: &quot;^save/Assign_49&quot;\\n  input: &quot;^save/Assign_50&quot;\\n  input: &quot;^save/Assign_51&quot;\\n  input: &quot;^save/Assign_52&quot;\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;accuracy/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9655452962954241&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xentropy & Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xent&Acc](misc/accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & bias distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![W&b](misc/weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histograms](misc/histograms.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
